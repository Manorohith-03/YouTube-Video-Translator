{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9954540649117245,
  "eval_steps": 500,
  "global_step": 42500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0035239806885858267,
      "grad_norm": 1.7029987573623657,
      "learning_rate": 4.994361630898263e-05,
      "loss": 2.4754,
      "step": 100
    },
    {
      "epoch": 0.0070479613771716534,
      "grad_norm": 1.0617727041244507,
      "learning_rate": 4.9884883297506195e-05,
      "loss": 0.3893,
      "step": 200
    },
    {
      "epoch": 0.01057194206575748,
      "grad_norm": 1.7092440128326416,
      "learning_rate": 4.982615028602976e-05,
      "loss": 0.3572,
      "step": 300
    },
    {
      "epoch": 0.014095922754343307,
      "grad_norm": 1.8670331239700317,
      "learning_rate": 4.9767417274553336e-05,
      "loss": 0.3657,
      "step": 400
    },
    {
      "epoch": 0.017619903442929134,
      "grad_norm": 1.1785376071929932,
      "learning_rate": 4.970868426307691e-05,
      "loss": 0.3669,
      "step": 500
    },
    {
      "epoch": 0.017619903442929134,
      "eval_loss": 0.2282317578792572,
      "eval_runtime": 32.9235,
      "eval_samples_per_second": 60.747,
      "eval_steps_per_second": 7.593,
      "step": 500
    },
    {
      "epoch": 0.02114388413151496,
      "grad_norm": 1.7851115465164185,
      "learning_rate": 4.964995125160048e-05,
      "loss": 0.3544,
      "step": 600
    },
    {
      "epoch": 0.024667864820100787,
      "grad_norm": 1.8377130031585693,
      "learning_rate": 4.959121824012405e-05,
      "loss": 0.3404,
      "step": 700
    },
    {
      "epoch": 0.028191845508686614,
      "grad_norm": 1.1547791957855225,
      "learning_rate": 4.953248522864762e-05,
      "loss": 0.3615,
      "step": 800
    },
    {
      "epoch": 0.03171582619727244,
      "grad_norm": 1.0430097579956055,
      "learning_rate": 4.9473752217171187e-05,
      "loss": 0.3269,
      "step": 900
    },
    {
      "epoch": 0.03523980688585827,
      "grad_norm": 0.9556300044059753,
      "learning_rate": 4.9415019205694754e-05,
      "loss": 0.3221,
      "step": 1000
    },
    {
      "epoch": 0.03523980688585827,
      "eval_loss": 0.21848490834236145,
      "eval_runtime": 31.3501,
      "eval_samples_per_second": 63.796,
      "eval_steps_per_second": 7.974,
      "step": 1000
    },
    {
      "epoch": 0.03876378757444409,
      "grad_norm": 1.671429991722107,
      "learning_rate": 4.935628619421833e-05,
      "loss": 0.3372,
      "step": 1100
    },
    {
      "epoch": 0.04228776826302992,
      "grad_norm": 1.97492253780365,
      "learning_rate": 4.9297553182741895e-05,
      "loss": 0.3063,
      "step": 1200
    },
    {
      "epoch": 0.045811748951615744,
      "grad_norm": 2.0220327377319336,
      "learning_rate": 4.923882017126546e-05,
      "loss": 0.3117,
      "step": 1300
    },
    {
      "epoch": 0.049335729640201574,
      "grad_norm": 1.2004764080047607,
      "learning_rate": 4.9180087159789037e-05,
      "loss": 0.3112,
      "step": 1400
    },
    {
      "epoch": 0.0528597103287874,
      "grad_norm": 1.174182415008545,
      "learning_rate": 4.9121354148312604e-05,
      "loss": 0.3316,
      "step": 1500
    },
    {
      "epoch": 0.0528597103287874,
      "eval_loss": 0.21310803294181824,
      "eval_runtime": 31.258,
      "eval_samples_per_second": 63.984,
      "eval_steps_per_second": 7.998,
      "step": 1500
    },
    {
      "epoch": 0.05638369101737323,
      "grad_norm": 0.8485285043716431,
      "learning_rate": 4.906262113683617e-05,
      "loss": 0.3134,
      "step": 1600
    },
    {
      "epoch": 0.05990767170595905,
      "grad_norm": 1.1120545864105225,
      "learning_rate": 4.9003888125359745e-05,
      "loss": 0.317,
      "step": 1700
    },
    {
      "epoch": 0.06343165239454487,
      "grad_norm": 1.0712634325027466,
      "learning_rate": 4.894515511388331e-05,
      "loss": 0.2979,
      "step": 1800
    },
    {
      "epoch": 0.06695563308313071,
      "grad_norm": 0.9769524931907654,
      "learning_rate": 4.888642210240688e-05,
      "loss": 0.3203,
      "step": 1900
    },
    {
      "epoch": 0.07047961377171653,
      "grad_norm": 1.1170880794525146,
      "learning_rate": 4.8827689090930454e-05,
      "loss": 0.2933,
      "step": 2000
    },
    {
      "epoch": 0.07047961377171653,
      "eval_loss": 0.21239523589611053,
      "eval_runtime": 31.2194,
      "eval_samples_per_second": 64.063,
      "eval_steps_per_second": 8.008,
      "step": 2000
    },
    {
      "epoch": 0.07400359446030236,
      "grad_norm": 1.501255989074707,
      "learning_rate": 4.876895607945402e-05,
      "loss": 0.3339,
      "step": 2100
    },
    {
      "epoch": 0.07752757514888818,
      "grad_norm": 0.7072989344596863,
      "learning_rate": 4.871022306797759e-05,
      "loss": 0.2937,
      "step": 2200
    },
    {
      "epoch": 0.081051555837474,
      "grad_norm": 1.0288958549499512,
      "learning_rate": 4.8651490056501156e-05,
      "loss": 0.3147,
      "step": 2300
    },
    {
      "epoch": 0.08457553652605984,
      "grad_norm": 1.4248850345611572,
      "learning_rate": 4.859275704502473e-05,
      "loss": 0.3118,
      "step": 2400
    },
    {
      "epoch": 0.08809951721464566,
      "grad_norm": 0.9843630790710449,
      "learning_rate": 4.85340240335483e-05,
      "loss": 0.3174,
      "step": 2500
    },
    {
      "epoch": 0.08809951721464566,
      "eval_loss": 0.2075173258781433,
      "eval_runtime": 31.2438,
      "eval_samples_per_second": 64.013,
      "eval_steps_per_second": 8.002,
      "step": 2500
    },
    {
      "epoch": 0.09162349790323149,
      "grad_norm": 1.770401954650879,
      "learning_rate": 4.8475291022071865e-05,
      "loss": 0.2828,
      "step": 2600
    },
    {
      "epoch": 0.09514747859181731,
      "grad_norm": 1.2375074625015259,
      "learning_rate": 4.841655801059544e-05,
      "loss": 0.2948,
      "step": 2700
    },
    {
      "epoch": 0.09867145928040315,
      "grad_norm": 1.1651440858840942,
      "learning_rate": 4.8357824999119006e-05,
      "loss": 0.2876,
      "step": 2800
    },
    {
      "epoch": 0.10219543996898897,
      "grad_norm": 1.403124451637268,
      "learning_rate": 4.829909198764257e-05,
      "loss": 0.2725,
      "step": 2900
    },
    {
      "epoch": 0.1057194206575748,
      "grad_norm": 0.9359010457992554,
      "learning_rate": 4.824035897616615e-05,
      "loss": 0.2722,
      "step": 3000
    },
    {
      "epoch": 0.1057194206575748,
      "eval_loss": 0.20959258079528809,
      "eval_runtime": 31.3174,
      "eval_samples_per_second": 63.862,
      "eval_steps_per_second": 7.983,
      "step": 3000
    },
    {
      "epoch": 0.10924340134616062,
      "grad_norm": 1.194650411605835,
      "learning_rate": 4.8181625964689715e-05,
      "loss": 0.2705,
      "step": 3100
    },
    {
      "epoch": 0.11276738203474646,
      "grad_norm": 1.642056941986084,
      "learning_rate": 4.812289295321328e-05,
      "loss": 0.2866,
      "step": 3200
    },
    {
      "epoch": 0.11629136272333228,
      "grad_norm": 1.0621702671051025,
      "learning_rate": 4.8064159941736856e-05,
      "loss": 0.2666,
      "step": 3300
    },
    {
      "epoch": 0.1198153434119181,
      "grad_norm": 1.5369378328323364,
      "learning_rate": 4.800542693026042e-05,
      "loss": 0.2845,
      "step": 3400
    },
    {
      "epoch": 0.12333932410050392,
      "grad_norm": 1.834131121635437,
      "learning_rate": 4.794669391878399e-05,
      "loss": 0.2648,
      "step": 3500
    },
    {
      "epoch": 0.12333932410050392,
      "eval_loss": 0.20580539107322693,
      "eval_runtime": 31.2947,
      "eval_samples_per_second": 63.909,
      "eval_steps_per_second": 7.989,
      "step": 3500
    },
    {
      "epoch": 0.12686330478908975,
      "grad_norm": 0.821558952331543,
      "learning_rate": 4.7887960907307565e-05,
      "loss": 0.2709,
      "step": 3600
    },
    {
      "epoch": 0.13038728547767559,
      "grad_norm": 1.7327901124954224,
      "learning_rate": 4.782922789583114e-05,
      "loss": 0.2676,
      "step": 3700
    },
    {
      "epoch": 0.13391126616626142,
      "grad_norm": 0.5939554572105408,
      "learning_rate": 4.7770494884354706e-05,
      "loss": 0.2548,
      "step": 3800
    },
    {
      "epoch": 0.13743524685484723,
      "grad_norm": 1.3659932613372803,
      "learning_rate": 4.771176187287827e-05,
      "loss": 0.2695,
      "step": 3900
    },
    {
      "epoch": 0.14095922754343307,
      "grad_norm": 0.984707236289978,
      "learning_rate": 4.765302886140184e-05,
      "loss": 0.256,
      "step": 4000
    },
    {
      "epoch": 0.14095922754343307,
      "eval_loss": 0.2045792192220688,
      "eval_runtime": 31.2419,
      "eval_samples_per_second": 64.017,
      "eval_steps_per_second": 8.002,
      "step": 4000
    },
    {
      "epoch": 0.14448320823201888,
      "grad_norm": 1.2921072244644165,
      "learning_rate": 4.7594295849925415e-05,
      "loss": 0.2486,
      "step": 4100
    },
    {
      "epoch": 0.14800718892060472,
      "grad_norm": 1.4746187925338745,
      "learning_rate": 4.753556283844898e-05,
      "loss": 0.2585,
      "step": 4200
    },
    {
      "epoch": 0.15153116960919055,
      "grad_norm": 1.4533107280731201,
      "learning_rate": 4.747682982697255e-05,
      "loss": 0.2651,
      "step": 4300
    },
    {
      "epoch": 0.15505515029777636,
      "grad_norm": 1.221219778060913,
      "learning_rate": 4.741809681549612e-05,
      "loss": 0.2524,
      "step": 4400
    },
    {
      "epoch": 0.1585791309863622,
      "grad_norm": 0.9532364010810852,
      "learning_rate": 4.735936380401969e-05,
      "loss": 0.2582,
      "step": 4500
    },
    {
      "epoch": 0.1585791309863622,
      "eval_loss": 0.2045530527830124,
      "eval_runtime": 31.2525,
      "eval_samples_per_second": 63.995,
      "eval_steps_per_second": 7.999,
      "step": 4500
    },
    {
      "epoch": 0.162103111674948,
      "grad_norm": 1.3230161666870117,
      "learning_rate": 4.730063079254326e-05,
      "loss": 0.2599,
      "step": 4600
    },
    {
      "epoch": 0.16562709236353385,
      "grad_norm": 1.4806830883026123,
      "learning_rate": 4.724189778106683e-05,
      "loss": 0.272,
      "step": 4700
    },
    {
      "epoch": 0.16915107305211968,
      "grad_norm": 1.333262324333191,
      "learning_rate": 4.71831647695904e-05,
      "loss": 0.2763,
      "step": 4800
    },
    {
      "epoch": 0.1726750537407055,
      "grad_norm": 1.1582881212234497,
      "learning_rate": 4.712443175811397e-05,
      "loss": 0.2644,
      "step": 4900
    },
    {
      "epoch": 0.17619903442929133,
      "grad_norm": 1.496456265449524,
      "learning_rate": 4.706569874663754e-05,
      "loss": 0.2362,
      "step": 5000
    },
    {
      "epoch": 0.17619903442929133,
      "eval_loss": 0.2054094523191452,
      "eval_runtime": 31.2195,
      "eval_samples_per_second": 64.063,
      "eval_steps_per_second": 8.008,
      "step": 5000
    },
    {
      "epoch": 0.17972301511787717,
      "grad_norm": 0.6664708852767944,
      "learning_rate": 4.700696573516111e-05,
      "loss": 0.2333,
      "step": 5100
    },
    {
      "epoch": 0.18324699580646298,
      "grad_norm": 0.9108873009681702,
      "learning_rate": 4.6948232723684675e-05,
      "loss": 0.2348,
      "step": 5200
    },
    {
      "epoch": 0.1867709764950488,
      "grad_norm": 1.390575885772705,
      "learning_rate": 4.688949971220824e-05,
      "loss": 0.2412,
      "step": 5300
    },
    {
      "epoch": 0.19029495718363462,
      "grad_norm": 1.2262883186340332,
      "learning_rate": 4.683076670073182e-05,
      "loss": 0.2477,
      "step": 5400
    },
    {
      "epoch": 0.19381893787222046,
      "grad_norm": 1.7990965843200684,
      "learning_rate": 4.6772033689255384e-05,
      "loss": 0.2503,
      "step": 5500
    },
    {
      "epoch": 0.19381893787222046,
      "eval_loss": 0.20182570815086365,
      "eval_runtime": 31.2834,
      "eval_samples_per_second": 63.932,
      "eval_steps_per_second": 7.991,
      "step": 5500
    },
    {
      "epoch": 0.1973429185608063,
      "grad_norm": 0.7179384231567383,
      "learning_rate": 4.671330067777895e-05,
      "loss": 0.2367,
      "step": 5600
    },
    {
      "epoch": 0.2008668992493921,
      "grad_norm": 1.219429612159729,
      "learning_rate": 4.6654567666302525e-05,
      "loss": 0.2202,
      "step": 5700
    },
    {
      "epoch": 0.20439087993797794,
      "grad_norm": 0.8751096725463867,
      "learning_rate": 4.659583465482609e-05,
      "loss": 0.2477,
      "step": 5800
    },
    {
      "epoch": 0.20791486062656378,
      "grad_norm": 1.378758192062378,
      "learning_rate": 4.653710164334966e-05,
      "loss": 0.2425,
      "step": 5900
    },
    {
      "epoch": 0.2114388413151496,
      "grad_norm": 0.7075948119163513,
      "learning_rate": 4.6478368631873234e-05,
      "loss": 0.2177,
      "step": 6000
    },
    {
      "epoch": 0.2114388413151496,
      "eval_loss": 0.2014349102973938,
      "eval_runtime": 31.2495,
      "eval_samples_per_second": 64.001,
      "eval_steps_per_second": 8.0,
      "step": 6000
    },
    {
      "epoch": 0.21496282200373543,
      "grad_norm": 1.4708333015441895,
      "learning_rate": 4.64196356203968e-05,
      "loss": 0.2214,
      "step": 6100
    },
    {
      "epoch": 0.21848680269232124,
      "grad_norm": 1.0636874437332153,
      "learning_rate": 4.636090260892037e-05,
      "loss": 0.23,
      "step": 6200
    },
    {
      "epoch": 0.22201078338090707,
      "grad_norm": 1.2218283414840698,
      "learning_rate": 4.630216959744394e-05,
      "loss": 0.2217,
      "step": 6300
    },
    {
      "epoch": 0.2255347640694929,
      "grad_norm": 0.8666996359825134,
      "learning_rate": 4.624343658596751e-05,
      "loss": 0.2222,
      "step": 6400
    },
    {
      "epoch": 0.22905874475807872,
      "grad_norm": 1.5098742246627808,
      "learning_rate": 4.618470357449108e-05,
      "loss": 0.2256,
      "step": 6500
    },
    {
      "epoch": 0.22905874475807872,
      "eval_loss": 0.20200905203819275,
      "eval_runtime": 31.2831,
      "eval_samples_per_second": 63.932,
      "eval_steps_per_second": 7.992,
      "step": 6500
    },
    {
      "epoch": 0.23258272544666456,
      "grad_norm": 1.0118731260299683,
      "learning_rate": 4.6125970563014645e-05,
      "loss": 0.2178,
      "step": 6600
    },
    {
      "epoch": 0.23610670613525037,
      "grad_norm": 0.9681286811828613,
      "learning_rate": 4.606723755153822e-05,
      "loss": 0.1994,
      "step": 6700
    },
    {
      "epoch": 0.2396306868238362,
      "grad_norm": 1.6323182582855225,
      "learning_rate": 4.600850454006179e-05,
      "loss": 0.2203,
      "step": 6800
    },
    {
      "epoch": 0.24315466751242204,
      "grad_norm": 1.4599865674972534,
      "learning_rate": 4.594977152858536e-05,
      "loss": 0.2252,
      "step": 6900
    },
    {
      "epoch": 0.24667864820100785,
      "grad_norm": 0.9563410878181458,
      "learning_rate": 4.5891038517108934e-05,
      "loss": 0.2222,
      "step": 7000
    },
    {
      "epoch": 0.24667864820100785,
      "eval_loss": 0.20350150763988495,
      "eval_runtime": 31.2321,
      "eval_samples_per_second": 64.037,
      "eval_steps_per_second": 8.005,
      "step": 7000
    },
    {
      "epoch": 0.25020262888959366,
      "grad_norm": 1.1481186151504517,
      "learning_rate": 4.58323055056325e-05,
      "loss": 0.2159,
      "step": 7100
    },
    {
      "epoch": 0.2537266095781795,
      "grad_norm": 1.085029125213623,
      "learning_rate": 4.577357249415607e-05,
      "loss": 0.2279,
      "step": 7200
    },
    {
      "epoch": 0.25725059026676533,
      "grad_norm": 2.079066514968872,
      "learning_rate": 4.5714839482679636e-05,
      "loss": 0.2181,
      "step": 7300
    },
    {
      "epoch": 0.26077457095535117,
      "grad_norm": 1.2149317264556885,
      "learning_rate": 4.565610647120321e-05,
      "loss": 0.2107,
      "step": 7400
    },
    {
      "epoch": 0.264298551643937,
      "grad_norm": 1.6930583715438843,
      "learning_rate": 4.559737345972678e-05,
      "loss": 0.2117,
      "step": 7500
    },
    {
      "epoch": 0.264298551643937,
      "eval_loss": 0.20338547229766846,
      "eval_runtime": 31.274,
      "eval_samples_per_second": 63.951,
      "eval_steps_per_second": 7.994,
      "step": 7500
    },
    {
      "epoch": 0.26782253233252284,
      "grad_norm": 0.7449666857719421,
      "learning_rate": 4.5538640448250345e-05,
      "loss": 0.2139,
      "step": 7600
    },
    {
      "epoch": 0.2713465130211086,
      "grad_norm": 1.228721022605896,
      "learning_rate": 4.547990743677392e-05,
      "loss": 0.2125,
      "step": 7700
    },
    {
      "epoch": 0.27487049370969446,
      "grad_norm": 1.5500187873840332,
      "learning_rate": 4.5421174425297486e-05,
      "loss": 0.2091,
      "step": 7800
    },
    {
      "epoch": 0.2783944743982803,
      "grad_norm": 1.0255554914474487,
      "learning_rate": 4.536244141382105e-05,
      "loss": 0.2149,
      "step": 7900
    },
    {
      "epoch": 0.28191845508686614,
      "grad_norm": 1.5438220500946045,
      "learning_rate": 4.530370840234463e-05,
      "loss": 0.2138,
      "step": 8000
    },
    {
      "epoch": 0.28191845508686614,
      "eval_loss": 0.2030581384897232,
      "eval_runtime": 31.2886,
      "eval_samples_per_second": 63.921,
      "eval_steps_per_second": 7.99,
      "step": 8000
    },
    {
      "epoch": 0.285442435775452,
      "grad_norm": 1.520193338394165,
      "learning_rate": 4.5244975390868195e-05,
      "loss": 0.2058,
      "step": 8100
    },
    {
      "epoch": 0.28896641646403776,
      "grad_norm": 1.5750881433486938,
      "learning_rate": 4.518624237939176e-05,
      "loss": 0.2074,
      "step": 8200
    },
    {
      "epoch": 0.2924903971526236,
      "grad_norm": 1.3231972455978394,
      "learning_rate": 4.512750936791533e-05,
      "loss": 0.1982,
      "step": 8300
    },
    {
      "epoch": 0.29601437784120943,
      "grad_norm": 1.4040093421936035,
      "learning_rate": 4.5068776356438903e-05,
      "loss": 0.1943,
      "step": 8400
    },
    {
      "epoch": 0.29953835852979527,
      "grad_norm": 0.8185247182846069,
      "learning_rate": 4.501004334496247e-05,
      "loss": 0.1928,
      "step": 8500
    },
    {
      "epoch": 0.29953835852979527,
      "eval_loss": 0.20284412801265717,
      "eval_runtime": 31.2938,
      "eval_samples_per_second": 63.91,
      "eval_steps_per_second": 7.989,
      "step": 8500
    },
    {
      "epoch": 0.3030623392183811,
      "grad_norm": 1.7901984453201294,
      "learning_rate": 4.495131033348604e-05,
      "loss": 0.195,
      "step": 8600
    },
    {
      "epoch": 0.3065863199069669,
      "grad_norm": 0.9463237524032593,
      "learning_rate": 4.489257732200961e-05,
      "loss": 0.1901,
      "step": 8700
    },
    {
      "epoch": 0.3101103005955527,
      "grad_norm": 0.9282979369163513,
      "learning_rate": 4.483384431053318e-05,
      "loss": 0.2104,
      "step": 8800
    },
    {
      "epoch": 0.31363428128413856,
      "grad_norm": 1.7955597639083862,
      "learning_rate": 4.477511129905675e-05,
      "loss": 0.2076,
      "step": 8900
    },
    {
      "epoch": 0.3171582619727244,
      "grad_norm": 1.2031985521316528,
      "learning_rate": 4.471637828758032e-05,
      "loss": 0.1814,
      "step": 9000
    },
    {
      "epoch": 0.3171582619727244,
      "eval_loss": 0.20451001822948456,
      "eval_runtime": 31.2543,
      "eval_samples_per_second": 63.991,
      "eval_steps_per_second": 7.999,
      "step": 9000
    },
    {
      "epoch": 0.32068224266131024,
      "grad_norm": 0.6255229115486145,
      "learning_rate": 4.465764527610389e-05,
      "loss": 0.1834,
      "step": 9100
    },
    {
      "epoch": 0.324206223349896,
      "grad_norm": 1.1563572883605957,
      "learning_rate": 4.4598912264627455e-05,
      "loss": 0.2031,
      "step": 9200
    },
    {
      "epoch": 0.32773020403848185,
      "grad_norm": 0.573265552520752,
      "learning_rate": 4.454017925315103e-05,
      "loss": 0.1842,
      "step": 9300
    },
    {
      "epoch": 0.3312541847270677,
      "grad_norm": 1.1069411039352417,
      "learning_rate": 4.44814462416746e-05,
      "loss": 0.1945,
      "step": 9400
    },
    {
      "epoch": 0.33477816541565353,
      "grad_norm": 0.6716412901878357,
      "learning_rate": 4.4422713230198164e-05,
      "loss": 0.192,
      "step": 9500
    },
    {
      "epoch": 0.33477816541565353,
      "eval_loss": 0.20032958686351776,
      "eval_runtime": 31.2533,
      "eval_samples_per_second": 63.993,
      "eval_steps_per_second": 7.999,
      "step": 9500
    },
    {
      "epoch": 0.33830214610423937,
      "grad_norm": 0.819672703742981,
      "learning_rate": 4.436398021872173e-05,
      "loss": 0.1923,
      "step": 9600
    },
    {
      "epoch": 0.3418261267928252,
      "grad_norm": 1.4974020719528198,
      "learning_rate": 4.4305247207245305e-05,
      "loss": 0.1942,
      "step": 9700
    },
    {
      "epoch": 0.345350107481411,
      "grad_norm": 0.8635780215263367,
      "learning_rate": 4.424651419576887e-05,
      "loss": 0.1795,
      "step": 9800
    },
    {
      "epoch": 0.3488740881699968,
      "grad_norm": 1.0244911909103394,
      "learning_rate": 4.418778118429245e-05,
      "loss": 0.1972,
      "step": 9900
    },
    {
      "epoch": 0.35239806885858266,
      "grad_norm": 1.2876718044281006,
      "learning_rate": 4.412904817281602e-05,
      "loss": 0.1795,
      "step": 10000
    },
    {
      "epoch": 0.35239806885858266,
      "eval_loss": 0.20268942415714264,
      "eval_runtime": 31.325,
      "eval_samples_per_second": 63.847,
      "eval_steps_per_second": 7.981,
      "step": 10000
    },
    {
      "epoch": 0.3559220495471685,
      "grad_norm": 1.2941203117370605,
      "learning_rate": 4.407031516133959e-05,
      "loss": 0.1799,
      "step": 10100
    },
    {
      "epoch": 0.35944603023575433,
      "grad_norm": 1.141217589378357,
      "learning_rate": 4.4011582149863155e-05,
      "loss": 0.1832,
      "step": 10200
    },
    {
      "epoch": 0.3629700109243401,
      "grad_norm": 0.8940626978874207,
      "learning_rate": 4.395284913838672e-05,
      "loss": 0.1762,
      "step": 10300
    },
    {
      "epoch": 0.36649399161292595,
      "grad_norm": 0.6755457520484924,
      "learning_rate": 4.38941161269103e-05,
      "loss": 0.178,
      "step": 10400
    },
    {
      "epoch": 0.3700179723015118,
      "grad_norm": 1.696928858757019,
      "learning_rate": 4.3835383115433864e-05,
      "loss": 0.1837,
      "step": 10500
    },
    {
      "epoch": 0.3700179723015118,
      "eval_loss": 0.20289838314056396,
      "eval_runtime": 31.1848,
      "eval_samples_per_second": 64.134,
      "eval_steps_per_second": 8.017,
      "step": 10500
    },
    {
      "epoch": 0.3735419529900976,
      "grad_norm": 1.584636926651001,
      "learning_rate": 4.377665010395743e-05,
      "loss": 0.1822,
      "step": 10600
    },
    {
      "epoch": 0.37706593367868346,
      "grad_norm": 0.51743084192276,
      "learning_rate": 4.3717917092481006e-05,
      "loss": 0.1694,
      "step": 10700
    },
    {
      "epoch": 0.38058991436726924,
      "grad_norm": 0.9063167572021484,
      "learning_rate": 4.365918408100457e-05,
      "loss": 0.157,
      "step": 10800
    },
    {
      "epoch": 0.3841138950558551,
      "grad_norm": 1.2305597066879272,
      "learning_rate": 4.360045106952814e-05,
      "loss": 0.1711,
      "step": 10900
    },
    {
      "epoch": 0.3876378757444409,
      "grad_norm": 0.5846813917160034,
      "learning_rate": 4.3541718058051714e-05,
      "loss": 0.1738,
      "step": 11000
    },
    {
      "epoch": 0.3876378757444409,
      "eval_loss": 0.20465023815631866,
      "eval_runtime": 31.1746,
      "eval_samples_per_second": 64.155,
      "eval_steps_per_second": 8.019,
      "step": 11000
    },
    {
      "epoch": 0.39116185643302676,
      "grad_norm": 0.6461546421051025,
      "learning_rate": 4.348298504657528e-05,
      "loss": 0.1722,
      "step": 11100
    },
    {
      "epoch": 0.3946858371216126,
      "grad_norm": 0.8703618049621582,
      "learning_rate": 4.342425203509885e-05,
      "loss": 0.177,
      "step": 11200
    },
    {
      "epoch": 0.3982098178101984,
      "grad_norm": 1.5530831813812256,
      "learning_rate": 4.336551902362242e-05,
      "loss": 0.1641,
      "step": 11300
    },
    {
      "epoch": 0.4017337984987842,
      "grad_norm": 1.1634294986724854,
      "learning_rate": 4.330678601214599e-05,
      "loss": 0.1615,
      "step": 11400
    },
    {
      "epoch": 0.40525777918737005,
      "grad_norm": 1.716914415359497,
      "learning_rate": 4.324805300066956e-05,
      "loss": 0.169,
      "step": 11500
    },
    {
      "epoch": 0.40525777918737005,
      "eval_loss": 0.20467889308929443,
      "eval_runtime": 31.1721,
      "eval_samples_per_second": 64.16,
      "eval_steps_per_second": 8.02,
      "step": 11500
    },
    {
      "epoch": 0.4087817598759559,
      "grad_norm": 0.9851769804954529,
      "learning_rate": 4.3189319989193125e-05,
      "loss": 0.1636,
      "step": 11600
    },
    {
      "epoch": 0.4123057405645417,
      "grad_norm": 1.3373117446899414,
      "learning_rate": 4.31305869777167e-05,
      "loss": 0.1552,
      "step": 11700
    },
    {
      "epoch": 0.41582972125312756,
      "grad_norm": 0.9681016206741333,
      "learning_rate": 4.3071853966240266e-05,
      "loss": 0.1646,
      "step": 11800
    },
    {
      "epoch": 0.41935370194171334,
      "grad_norm": 1.0431584119796753,
      "learning_rate": 4.3013120954763833e-05,
      "loss": 0.1476,
      "step": 11900
    },
    {
      "epoch": 0.4228776826302992,
      "grad_norm": 0.8434838652610779,
      "learning_rate": 4.295438794328741e-05,
      "loss": 0.1575,
      "step": 12000
    },
    {
      "epoch": 0.4228776826302992,
      "eval_loss": 0.2057490050792694,
      "eval_runtime": 31.186,
      "eval_samples_per_second": 64.131,
      "eval_steps_per_second": 8.016,
      "step": 12000
    },
    {
      "epoch": 0.426401663318885,
      "grad_norm": 1.9762970209121704,
      "learning_rate": 4.2895654931810975e-05,
      "loss": 0.1652,
      "step": 12100
    },
    {
      "epoch": 0.42992564400747085,
      "grad_norm": 1.268369436264038,
      "learning_rate": 4.283692192033454e-05,
      "loss": 0.1686,
      "step": 12200
    },
    {
      "epoch": 0.4334496246960567,
      "grad_norm": 1.2125173807144165,
      "learning_rate": 4.2778188908858116e-05,
      "loss": 0.1626,
      "step": 12300
    },
    {
      "epoch": 0.43697360538464247,
      "grad_norm": 1.0405653715133667,
      "learning_rate": 4.2719455897381683e-05,
      "loss": 0.161,
      "step": 12400
    },
    {
      "epoch": 0.4404975860732283,
      "grad_norm": 0.9440110325813293,
      "learning_rate": 4.266072288590525e-05,
      "loss": 0.1612,
      "step": 12500
    },
    {
      "epoch": 0.4404975860732283,
      "eval_loss": 0.2071186900138855,
      "eval_runtime": 31.1264,
      "eval_samples_per_second": 64.254,
      "eval_steps_per_second": 8.032,
      "step": 12500
    },
    {
      "epoch": 0.44402156676181415,
      "grad_norm": 0.9377078413963318,
      "learning_rate": 4.2601989874428825e-05,
      "loss": 0.1635,
      "step": 12600
    },
    {
      "epoch": 0.4475455474504,
      "grad_norm": 0.9623863101005554,
      "learning_rate": 4.254325686295239e-05,
      "loss": 0.1564,
      "step": 12700
    },
    {
      "epoch": 0.4510695281389858,
      "grad_norm": 0.5684788823127747,
      "learning_rate": 4.248452385147596e-05,
      "loss": 0.1569,
      "step": 12800
    },
    {
      "epoch": 0.4545935088275716,
      "grad_norm": 0.6391335129737854,
      "learning_rate": 4.242579083999953e-05,
      "loss": 0.1457,
      "step": 12900
    },
    {
      "epoch": 0.45811748951615744,
      "grad_norm": 1.0596418380737305,
      "learning_rate": 4.23670578285231e-05,
      "loss": 0.1503,
      "step": 13000
    },
    {
      "epoch": 0.45811748951615744,
      "eval_loss": 0.20726753771305084,
      "eval_runtime": 31.1641,
      "eval_samples_per_second": 64.176,
      "eval_steps_per_second": 8.022,
      "step": 13000
    },
    {
      "epoch": 0.4616414702047433,
      "grad_norm": 0.740053117275238,
      "learning_rate": 4.2308324817046675e-05,
      "loss": 0.1501,
      "step": 13100
    },
    {
      "epoch": 0.4651654508933291,
      "grad_norm": 1.4571870565414429,
      "learning_rate": 4.224959180557024e-05,
      "loss": 0.1539,
      "step": 13200
    },
    {
      "epoch": 0.46868943158191495,
      "grad_norm": 0.7553426027297974,
      "learning_rate": 4.219085879409381e-05,
      "loss": 0.1563,
      "step": 13300
    },
    {
      "epoch": 0.47221341227050073,
      "grad_norm": 1.2339355945587158,
      "learning_rate": 4.2132125782617384e-05,
      "loss": 0.1443,
      "step": 13400
    },
    {
      "epoch": 0.47573739295908657,
      "grad_norm": 1.0668975114822388,
      "learning_rate": 4.207339277114095e-05,
      "loss": 0.1569,
      "step": 13500
    },
    {
      "epoch": 0.47573739295908657,
      "eval_loss": 0.20588110387325287,
      "eval_runtime": 31.1673,
      "eval_samples_per_second": 64.17,
      "eval_steps_per_second": 8.021,
      "step": 13500
    },
    {
      "epoch": 0.4792613736476724,
      "grad_norm": 0.7249481678009033,
      "learning_rate": 4.201465975966452e-05,
      "loss": 0.146,
      "step": 13600
    },
    {
      "epoch": 0.48278535433625824,
      "grad_norm": 0.7035710215568542,
      "learning_rate": 4.195592674818809e-05,
      "loss": 0.1541,
      "step": 13700
    },
    {
      "epoch": 0.4863093350248441,
      "grad_norm": 1.088613748550415,
      "learning_rate": 4.189719373671166e-05,
      "loss": 0.1423,
      "step": 13800
    },
    {
      "epoch": 0.4898333157134299,
      "grad_norm": 0.6346660256385803,
      "learning_rate": 4.183846072523523e-05,
      "loss": 0.1338,
      "step": 13900
    },
    {
      "epoch": 0.4933572964020157,
      "grad_norm": 0.9756304025650024,
      "learning_rate": 4.17797277137588e-05,
      "loss": 0.1376,
      "step": 14000
    },
    {
      "epoch": 0.4933572964020157,
      "eval_loss": 0.20890918374061584,
      "eval_runtime": 31.1628,
      "eval_samples_per_second": 64.179,
      "eval_steps_per_second": 8.022,
      "step": 14000
    },
    {
      "epoch": 0.49688127709060154,
      "grad_norm": 1.1069176197052002,
      "learning_rate": 4.172099470228237e-05,
      "loss": 0.1466,
      "step": 14100
    },
    {
      "epoch": 0.5004052577791873,
      "grad_norm": 0.917344331741333,
      "learning_rate": 4.1662261690805936e-05,
      "loss": 0.1404,
      "step": 14200
    },
    {
      "epoch": 0.5039292384677732,
      "grad_norm": 0.6606826782226562,
      "learning_rate": 4.160352867932951e-05,
      "loss": 0.1345,
      "step": 14300
    },
    {
      "epoch": 0.507453219156359,
      "grad_norm": 0.6334942579269409,
      "learning_rate": 4.154479566785308e-05,
      "loss": 0.1502,
      "step": 14400
    },
    {
      "epoch": 0.5109771998449448,
      "grad_norm": 2.179875373840332,
      "learning_rate": 4.1486062656376644e-05,
      "loss": 0.149,
      "step": 14500
    },
    {
      "epoch": 0.5109771998449448,
      "eval_loss": 0.2078515887260437,
      "eval_runtime": 31.118,
      "eval_samples_per_second": 64.272,
      "eval_steps_per_second": 8.034,
      "step": 14500
    },
    {
      "epoch": 0.5145011805335307,
      "grad_norm": 0.8990302681922913,
      "learning_rate": 4.142732964490021e-05,
      "loss": 0.1563,
      "step": 14600
    },
    {
      "epoch": 0.5180251612221165,
      "grad_norm": 0.7009998559951782,
      "learning_rate": 4.1368596633423786e-05,
      "loss": 0.1454,
      "step": 14700
    },
    {
      "epoch": 0.5215491419107023,
      "grad_norm": 0.7928536534309387,
      "learning_rate": 4.130986362194735e-05,
      "loss": 0.1321,
      "step": 14800
    },
    {
      "epoch": 0.5250731225992882,
      "grad_norm": 0.9384068846702576,
      "learning_rate": 4.125113061047092e-05,
      "loss": 0.1442,
      "step": 14900
    },
    {
      "epoch": 0.528597103287874,
      "grad_norm": 1.3658384084701538,
      "learning_rate": 4.1192397598994494e-05,
      "loss": 0.136,
      "step": 15000
    },
    {
      "epoch": 0.528597103287874,
      "eval_loss": 0.21102169156074524,
      "eval_runtime": 31.1279,
      "eval_samples_per_second": 64.251,
      "eval_steps_per_second": 8.031,
      "step": 15000
    },
    {
      "epoch": 0.5321210839764599,
      "grad_norm": 1.229323387145996,
      "learning_rate": 4.113366458751806e-05,
      "loss": 0.1454,
      "step": 15100
    },
    {
      "epoch": 0.5356450646650457,
      "grad_norm": 1.0546077489852905,
      "learning_rate": 4.107493157604163e-05,
      "loss": 0.1325,
      "step": 15200
    },
    {
      "epoch": 0.5391690453536314,
      "grad_norm": 1.6252994537353516,
      "learning_rate": 4.10161985645652e-05,
      "loss": 0.1355,
      "step": 15300
    },
    {
      "epoch": 0.5426930260422173,
      "grad_norm": 0.7134121656417847,
      "learning_rate": 4.095746555308877e-05,
      "loss": 0.137,
      "step": 15400
    },
    {
      "epoch": 0.5462170067308031,
      "grad_norm": 1.1498242616653442,
      "learning_rate": 4.089873254161234e-05,
      "loss": 0.1329,
      "step": 15500
    },
    {
      "epoch": 0.5462170067308031,
      "eval_loss": 0.21278269588947296,
      "eval_runtime": 31.2822,
      "eval_samples_per_second": 63.934,
      "eval_steps_per_second": 7.992,
      "step": 15500
    },
    {
      "epoch": 0.5497409874193889,
      "grad_norm": 0.7204769849777222,
      "learning_rate": 4.083999953013591e-05,
      "loss": 0.1417,
      "step": 15600
    },
    {
      "epoch": 0.5532649681079748,
      "grad_norm": 0.8115714192390442,
      "learning_rate": 4.078126651865948e-05,
      "loss": 0.1281,
      "step": 15700
    },
    {
      "epoch": 0.5567889487965606,
      "grad_norm": 0.9477105140686035,
      "learning_rate": 4.0722533507183046e-05,
      "loss": 0.1294,
      "step": 15800
    },
    {
      "epoch": 0.5603129294851464,
      "grad_norm": 0.8692101836204529,
      "learning_rate": 4.0663800495706614e-05,
      "loss": 0.1323,
      "step": 15900
    },
    {
      "epoch": 0.5638369101737323,
      "grad_norm": 0.7750817537307739,
      "learning_rate": 4.060506748423019e-05,
      "loss": 0.1292,
      "step": 16000
    },
    {
      "epoch": 0.5638369101737323,
      "eval_loss": 0.2107667177915573,
      "eval_runtime": 31.3305,
      "eval_samples_per_second": 63.836,
      "eval_steps_per_second": 7.979,
      "step": 16000
    },
    {
      "epoch": 0.5673608908623181,
      "grad_norm": 1.1209789514541626,
      "learning_rate": 4.0546334472753755e-05,
      "loss": 0.1327,
      "step": 16100
    },
    {
      "epoch": 0.570884871550904,
      "grad_norm": 0.7144445776939392,
      "learning_rate": 4.048760146127733e-05,
      "loss": 0.1295,
      "step": 16200
    },
    {
      "epoch": 0.5744088522394897,
      "grad_norm": 0.6798661351203918,
      "learning_rate": 4.0428868449800896e-05,
      "loss": 0.1277,
      "step": 16300
    },
    {
      "epoch": 0.5779328329280755,
      "grad_norm": 1.0841041803359985,
      "learning_rate": 4.037013543832447e-05,
      "loss": 0.1258,
      "step": 16400
    },
    {
      "epoch": 0.5814568136166613,
      "grad_norm": 1.2426269054412842,
      "learning_rate": 4.031140242684804e-05,
      "loss": 0.1289,
      "step": 16500
    },
    {
      "epoch": 0.5814568136166613,
      "eval_loss": 0.21171808242797852,
      "eval_runtime": 31.1262,
      "eval_samples_per_second": 64.254,
      "eval_steps_per_second": 8.032,
      "step": 16500
    },
    {
      "epoch": 0.5849807943052472,
      "grad_norm": 0.9058093428611755,
      "learning_rate": 4.0252669415371605e-05,
      "loss": 0.1247,
      "step": 16600
    },
    {
      "epoch": 0.588504774993833,
      "grad_norm": 1.2471976280212402,
      "learning_rate": 4.019393640389518e-05,
      "loss": 0.1241,
      "step": 16700
    },
    {
      "epoch": 0.5920287556824189,
      "grad_norm": 0.5778094530105591,
      "learning_rate": 4.0135203392418746e-05,
      "loss": 0.1425,
      "step": 16800
    },
    {
      "epoch": 0.5955527363710047,
      "grad_norm": 1.037530541419983,
      "learning_rate": 4.0076470380942314e-05,
      "loss": 0.1216,
      "step": 16900
    },
    {
      "epoch": 0.5990767170595905,
      "grad_norm": 0.9149721264839172,
      "learning_rate": 4.001773736946589e-05,
      "loss": 0.1097,
      "step": 17000
    },
    {
      "epoch": 0.5990767170595905,
      "eval_loss": 0.21144422888755798,
      "eval_runtime": 30.9793,
      "eval_samples_per_second": 64.559,
      "eval_steps_per_second": 8.07,
      "step": 17000
    },
    {
      "epoch": 0.6026006977481764,
      "grad_norm": 0.9354404807090759,
      "learning_rate": 3.9959004357989455e-05,
      "loss": 0.1323,
      "step": 17100
    },
    {
      "epoch": 0.6061246784367622,
      "grad_norm": 1.481238603591919,
      "learning_rate": 3.990027134651302e-05,
      "loss": 0.1256,
      "step": 17200
    },
    {
      "epoch": 0.609648659125348,
      "grad_norm": 0.9301944971084595,
      "learning_rate": 3.9841538335036596e-05,
      "loss": 0.1242,
      "step": 17300
    },
    {
      "epoch": 0.6131726398139338,
      "grad_norm": 0.8921674489974976,
      "learning_rate": 3.9782805323560164e-05,
      "loss": 0.1201,
      "step": 17400
    },
    {
      "epoch": 0.6166966205025196,
      "grad_norm": 0.7442641854286194,
      "learning_rate": 3.972407231208373e-05,
      "loss": 0.1349,
      "step": 17500
    },
    {
      "epoch": 0.6166966205025196,
      "eval_loss": 0.2119932621717453,
      "eval_runtime": 31.0619,
      "eval_samples_per_second": 64.388,
      "eval_steps_per_second": 8.048,
      "step": 17500
    },
    {
      "epoch": 1.2404764421890968,
      "grad_norm": 0.9819837212562561,
      "learning_rate": 2.932995019265107e-05,
      "loss": 0.1002,
      "step": 17600
    },
    {
      "epoch": 1.2475244035662685,
      "grad_norm": 0.6748325228691101,
      "learning_rate": 2.9212480030072364e-05,
      "loss": 0.0918,
      "step": 17700
    },
    {
      "epoch": 1.2545723649434402,
      "grad_norm": 0.6101155281066895,
      "learning_rate": 2.9095009867493655e-05,
      "loss": 0.0955,
      "step": 17800
    },
    {
      "epoch": 1.2616203263206118,
      "grad_norm": 0.3833466172218323,
      "learning_rate": 2.8977539704914952e-05,
      "loss": 0.083,
      "step": 17900
    },
    {
      "epoch": 1.2686682876977833,
      "grad_norm": 0.3217647075653076,
      "learning_rate": 2.886006954233625e-05,
      "loss": 0.0907,
      "step": 18000
    },
    {
      "epoch": 1.2686682876977833,
      "eval_loss": 0.20799694955348969,
      "eval_runtime": 37.1477,
      "eval_samples_per_second": 53.839,
      "eval_steps_per_second": 13.46,
      "step": 18000
    },
    {
      "epoch": 1.275716249074955,
      "grad_norm": 0.4594741761684418,
      "learning_rate": 2.8742599379757544e-05,
      "loss": 0.0938,
      "step": 18100
    },
    {
      "epoch": 1.2827642104521266,
      "grad_norm": 0.6941646933555603,
      "learning_rate": 2.8625129217178835e-05,
      "loss": 0.0812,
      "step": 18200
    },
    {
      "epoch": 1.2898121718292983,
      "grad_norm": 0.45940297842025757,
      "learning_rate": 2.8507659054600133e-05,
      "loss": 0.0875,
      "step": 18300
    },
    {
      "epoch": 1.29686013320647,
      "grad_norm": 0.5200314521789551,
      "learning_rate": 2.839018889202143e-05,
      "loss": 0.0968,
      "step": 18400
    },
    {
      "epoch": 1.3039080945836417,
      "grad_norm": 0.5181090235710144,
      "learning_rate": 2.827271872944272e-05,
      "loss": 0.0857,
      "step": 18500
    },
    {
      "epoch": 1.3039080945836417,
      "eval_loss": 0.21000683307647705,
      "eval_runtime": 37.1321,
      "eval_samples_per_second": 53.862,
      "eval_steps_per_second": 13.465,
      "step": 18500
    },
    {
      "epoch": 1.3109560559608133,
      "grad_norm": 0.49014168977737427,
      "learning_rate": 2.815524856686402e-05,
      "loss": 0.0892,
      "step": 18600
    },
    {
      "epoch": 1.318004017337985,
      "grad_norm": 0.5888361930847168,
      "learning_rate": 2.8037778404285313e-05,
      "loss": 0.0919,
      "step": 18700
    },
    {
      "epoch": 1.3250519787151567,
      "grad_norm": 0.6106946468353271,
      "learning_rate": 2.7920308241706604e-05,
      "loss": 0.085,
      "step": 18800
    },
    {
      "epoch": 1.3320999400923283,
      "grad_norm": 0.4971104562282562,
      "learning_rate": 2.7802838079127902e-05,
      "loss": 0.0862,
      "step": 18900
    },
    {
      "epoch": 1.3391479014695,
      "grad_norm": 0.4777922034263611,
      "learning_rate": 2.76853679165492e-05,
      "loss": 0.0829,
      "step": 19000
    },
    {
      "epoch": 1.3391479014695,
      "eval_loss": 0.20779651403427124,
      "eval_runtime": 36.9309,
      "eval_samples_per_second": 54.155,
      "eval_steps_per_second": 13.539,
      "step": 19000
    },
    {
      "epoch": 1.3461958628466717,
      "grad_norm": 0.6201363801956177,
      "learning_rate": 2.7567897753970494e-05,
      "loss": 0.0801,
      "step": 19100
    },
    {
      "epoch": 1.3532438242238434,
      "grad_norm": 0.5389255881309509,
      "learning_rate": 2.7450427591391788e-05,
      "loss": 0.0851,
      "step": 19200
    },
    {
      "epoch": 1.3602917856010148,
      "grad_norm": 0.5057684779167175,
      "learning_rate": 2.7332957428813082e-05,
      "loss": 0.0844,
      "step": 19300
    },
    {
      "epoch": 1.3673397469781865,
      "grad_norm": 0.5690885782241821,
      "learning_rate": 2.721548726623438e-05,
      "loss": 0.0847,
      "step": 19400
    },
    {
      "epoch": 1.3743877083553582,
      "grad_norm": 0.4167630970478058,
      "learning_rate": 2.709801710365567e-05,
      "loss": 0.0847,
      "step": 19500
    },
    {
      "epoch": 1.3743877083553582,
      "eval_loss": 0.20972909033298492,
      "eval_runtime": 37.1288,
      "eval_samples_per_second": 53.867,
      "eval_steps_per_second": 13.467,
      "step": 19500
    },
    {
      "epoch": 1.3814356697325298,
      "grad_norm": 0.48481935262680054,
      "learning_rate": 2.698054694107697e-05,
      "loss": 0.0855,
      "step": 19600
    },
    {
      "epoch": 1.3884836311097015,
      "grad_norm": 0.6710375547409058,
      "learning_rate": 2.6863076778498263e-05,
      "loss": 0.0758,
      "step": 19700
    },
    {
      "epoch": 1.3955315924868732,
      "grad_norm": 0.44488611817359924,
      "learning_rate": 2.6745606615919554e-05,
      "loss": 0.0789,
      "step": 19800
    },
    {
      "epoch": 1.4025795538640449,
      "grad_norm": 0.4084774851799011,
      "learning_rate": 2.662813645334085e-05,
      "loss": 0.0743,
      "step": 19900
    },
    {
      "epoch": 1.4096275152412165,
      "grad_norm": 0.4456728398799896,
      "learning_rate": 2.651066629076215e-05,
      "loss": 0.077,
      "step": 20000
    },
    {
      "epoch": 1.4096275152412165,
      "eval_loss": 0.20988228917121887,
      "eval_runtime": 38.1684,
      "eval_samples_per_second": 52.399,
      "eval_steps_per_second": 13.1,
      "step": 20000
    },
    {
      "epoch": 1.416675476618388,
      "grad_norm": 0.5943949222564697,
      "learning_rate": 2.6393196128183447e-05,
      "loss": 0.083,
      "step": 20100
    },
    {
      "epoch": 1.4237234379955597,
      "grad_norm": 0.5707781314849854,
      "learning_rate": 2.6275725965604737e-05,
      "loss": 0.0758,
      "step": 20200
    },
    {
      "epoch": 1.4307713993727313,
      "grad_norm": 0.6734489798545837,
      "learning_rate": 2.615825580302603e-05,
      "loss": 0.0829,
      "step": 20300
    },
    {
      "epoch": 1.437819360749903,
      "grad_norm": 0.4356894791126251,
      "learning_rate": 2.604078564044733e-05,
      "loss": 0.0795,
      "step": 20400
    },
    {
      "epoch": 1.4448673221270747,
      "grad_norm": 0.4554043412208557,
      "learning_rate": 2.592331547786862e-05,
      "loss": 0.0784,
      "step": 20500
    },
    {
      "epoch": 1.4448673221270747,
      "eval_loss": 0.21078293025493622,
      "eval_runtime": 38.1885,
      "eval_samples_per_second": 52.372,
      "eval_steps_per_second": 13.093,
      "step": 20500
    },
    {
      "epoch": 1.4519152835042464,
      "grad_norm": 0.4702342450618744,
      "learning_rate": 2.5805845315289918e-05,
      "loss": 0.0777,
      "step": 20600
    },
    {
      "epoch": 1.458963244881418,
      "grad_norm": 0.4687262773513794,
      "learning_rate": 2.5688375152711212e-05,
      "loss": 0.0765,
      "step": 20700
    },
    {
      "epoch": 1.4660112062585897,
      "grad_norm": 0.4446411728858948,
      "learning_rate": 2.5570904990132506e-05,
      "loss": 0.0812,
      "step": 20800
    },
    {
      "epoch": 1.4730591676357614,
      "grad_norm": 0.6139910221099854,
      "learning_rate": 2.54534348275538e-05,
      "loss": 0.0758,
      "step": 20900
    },
    {
      "epoch": 1.480107129012933,
      "grad_norm": 0.4039977192878723,
      "learning_rate": 2.5335964664975098e-05,
      "loss": 0.0789,
      "step": 21000
    },
    {
      "epoch": 1.480107129012933,
      "eval_loss": 0.21247310936450958,
      "eval_runtime": 37.9623,
      "eval_samples_per_second": 52.684,
      "eval_steps_per_second": 13.171,
      "step": 21000
    },
    {
      "epoch": 1.4871550903901047,
      "grad_norm": 0.5268082618713379,
      "learning_rate": 2.5218494502396396e-05,
      "loss": 0.0752,
      "step": 21100
    },
    {
      "epoch": 1.4942030517672764,
      "grad_norm": 0.4849323332309723,
      "learning_rate": 2.5101024339817687e-05,
      "loss": 0.0758,
      "step": 21200
    },
    {
      "epoch": 1.501251013144448,
      "grad_norm": 0.7631898522377014,
      "learning_rate": 2.498355417723898e-05,
      "loss": 0.0796,
      "step": 21300
    },
    {
      "epoch": 1.5082989745216198,
      "grad_norm": 0.48087185621261597,
      "learning_rate": 2.4866084014660275e-05,
      "loss": 0.0748,
      "step": 21400
    },
    {
      "epoch": 1.5153469358987914,
      "grad_norm": 0.47181832790374756,
      "learning_rate": 2.4748613852081573e-05,
      "loss": 0.0779,
      "step": 21500
    },
    {
      "epoch": 1.5153469358987914,
      "eval_loss": 0.2127724438905716,
      "eval_runtime": 38.1291,
      "eval_samples_per_second": 52.453,
      "eval_steps_per_second": 13.113,
      "step": 21500
    },
    {
      "epoch": 1.5223948972759629,
      "grad_norm": 0.49572259187698364,
      "learning_rate": 2.4631143689502867e-05,
      "loss": 0.0792,
      "step": 21600
    },
    {
      "epoch": 1.5294428586531346,
      "grad_norm": 0.37643498182296753,
      "learning_rate": 2.4513673526924165e-05,
      "loss": 0.0733,
      "step": 21700
    },
    {
      "epoch": 1.5364908200303062,
      "grad_norm": 0.4383210241794586,
      "learning_rate": 2.4396203364345456e-05,
      "loss": 0.0681,
      "step": 21800
    },
    {
      "epoch": 1.543538781407478,
      "grad_norm": 0.4066198170185089,
      "learning_rate": 2.427873320176675e-05,
      "loss": 0.0774,
      "step": 21900
    },
    {
      "epoch": 1.5505867427846496,
      "grad_norm": 0.3828258216381073,
      "learning_rate": 2.4161263039188048e-05,
      "loss": 0.0732,
      "step": 22000
    },
    {
      "epoch": 1.5505867427846496,
      "eval_loss": 0.21226058900356293,
      "eval_runtime": 37.8274,
      "eval_samples_per_second": 52.872,
      "eval_steps_per_second": 13.218,
      "step": 22000
    },
    {
      "epoch": 1.557634704161821,
      "grad_norm": 0.5264379382133484,
      "learning_rate": 2.4043792876609342e-05,
      "loss": 0.0745,
      "step": 22100
    },
    {
      "epoch": 1.5646826655389927,
      "grad_norm": 0.382011741399765,
      "learning_rate": 2.392632271403064e-05,
      "loss": 0.0736,
      "step": 22200
    },
    {
      "epoch": 1.5717306269161644,
      "grad_norm": 0.37205594778060913,
      "learning_rate": 2.3808852551451934e-05,
      "loss": 0.0709,
      "step": 22300
    },
    {
      "epoch": 1.578778588293336,
      "grad_norm": 0.5117428302764893,
      "learning_rate": 2.3691382388873225e-05,
      "loss": 0.0725,
      "step": 22400
    },
    {
      "epoch": 1.5858265496705077,
      "grad_norm": 0.5829002261161804,
      "learning_rate": 2.3573912226294522e-05,
      "loss": 0.074,
      "step": 22500
    },
    {
      "epoch": 1.5858265496705077,
      "eval_loss": 0.21106906235218048,
      "eval_runtime": 37.7931,
      "eval_samples_per_second": 52.92,
      "eval_steps_per_second": 13.23,
      "step": 22500
    },
    {
      "epoch": 1.5928745110476794,
      "grad_norm": 0.45786672830581665,
      "learning_rate": 2.3456442063715817e-05,
      "loss": 0.0762,
      "step": 22600
    },
    {
      "epoch": 1.599922472424851,
      "grad_norm": 0.46573445200920105,
      "learning_rate": 2.3338971901137114e-05,
      "loss": 0.0689,
      "step": 22700
    },
    {
      "epoch": 1.6069704338020228,
      "grad_norm": 0.39763206243515015,
      "learning_rate": 2.322150173855841e-05,
      "loss": 0.0682,
      "step": 22800
    },
    {
      "epoch": 1.6140183951791944,
      "grad_norm": 0.45704591274261475,
      "learning_rate": 2.31040315759797e-05,
      "loss": 0.0677,
      "step": 22900
    },
    {
      "epoch": 1.621066356556366,
      "grad_norm": 0.41902390122413635,
      "learning_rate": 2.2986561413400997e-05,
      "loss": 0.0698,
      "step": 23000
    },
    {
      "epoch": 1.621066356556366,
      "eval_loss": 0.21289321780204773,
      "eval_runtime": 38.0753,
      "eval_samples_per_second": 52.527,
      "eval_steps_per_second": 13.132,
      "step": 23000
    },
    {
      "epoch": 1.6281143179335378,
      "grad_norm": 0.6051429510116577,
      "learning_rate": 2.286909125082229e-05,
      "loss": 0.0766,
      "step": 23100
    },
    {
      "epoch": 1.6351622793107095,
      "grad_norm": 0.6250931620597839,
      "learning_rate": 2.275162108824359e-05,
      "loss": 0.069,
      "step": 23200
    },
    {
      "epoch": 1.6422102406878811,
      "grad_norm": 0.31753772497177124,
      "learning_rate": 2.2634150925664883e-05,
      "loss": 0.0735,
      "step": 23300
    },
    {
      "epoch": 1.6492582020650528,
      "grad_norm": 0.45319774746894836,
      "learning_rate": 2.2516680763086174e-05,
      "loss": 0.0743,
      "step": 23400
    },
    {
      "epoch": 1.6563061634422245,
      "grad_norm": 0.5308738946914673,
      "learning_rate": 2.2399210600507472e-05,
      "loss": 0.0749,
      "step": 23500
    },
    {
      "epoch": 1.6563061634422245,
      "eval_loss": 0.21428282558918,
      "eval_runtime": 37.7696,
      "eval_samples_per_second": 52.953,
      "eval_steps_per_second": 13.238,
      "step": 23500
    },
    {
      "epoch": 1.6633541248193962,
      "grad_norm": 0.5740648508071899,
      "learning_rate": 2.2281740437928766e-05,
      "loss": 0.0741,
      "step": 23600
    },
    {
      "epoch": 1.6704020861965676,
      "grad_norm": 0.5477343797683716,
      "learning_rate": 2.2164270275350064e-05,
      "loss": 0.0746,
      "step": 23700
    },
    {
      "epoch": 1.6774500475737393,
      "grad_norm": 0.4092574417591095,
      "learning_rate": 2.2046800112771358e-05,
      "loss": 0.0691,
      "step": 23800
    },
    {
      "epoch": 1.684498008950911,
      "grad_norm": 0.3480450212955475,
      "learning_rate": 2.1929329950192652e-05,
      "loss": 0.0655,
      "step": 23900
    },
    {
      "epoch": 1.6915459703280826,
      "grad_norm": 0.3131400942802429,
      "learning_rate": 2.1811859787613947e-05,
      "loss": 0.0667,
      "step": 24000
    },
    {
      "epoch": 1.6915459703280826,
      "eval_loss": 0.21533650159835815,
      "eval_runtime": 37.7421,
      "eval_samples_per_second": 52.991,
      "eval_steps_per_second": 13.248,
      "step": 24000
    },
    {
      "epoch": 1.6985939317052543,
      "grad_norm": 0.6256730556488037,
      "learning_rate": 2.169438962503524e-05,
      "loss": 0.0653,
      "step": 24100
    },
    {
      "epoch": 1.7056418930824258,
      "grad_norm": 0.5310169458389282,
      "learning_rate": 2.157691946245654e-05,
      "loss": 0.0756,
      "step": 24200
    },
    {
      "epoch": 1.7126898544595974,
      "grad_norm": 0.4070800542831421,
      "learning_rate": 2.1459449299877833e-05,
      "loss": 0.0721,
      "step": 24300
    },
    {
      "epoch": 1.719737815836769,
      "grad_norm": 0.5194215774536133,
      "learning_rate": 2.1341979137299127e-05,
      "loss": 0.0702,
      "step": 24400
    },
    {
      "epoch": 1.7267857772139408,
      "grad_norm": 0.41986697912216187,
      "learning_rate": 2.122450897472042e-05,
      "loss": 0.0748,
      "step": 24500
    },
    {
      "epoch": 1.7267857772139408,
      "eval_loss": 0.21351006627082825,
      "eval_runtime": 37.6848,
      "eval_samples_per_second": 53.072,
      "eval_steps_per_second": 13.268,
      "step": 24500
    },
    {
      "epoch": 1.7338337385911124,
      "grad_norm": 0.3741745948791504,
      "learning_rate": 2.1107038812141716e-05,
      "loss": 0.0667,
      "step": 24600
    },
    {
      "epoch": 1.7408816999682841,
      "grad_norm": 0.38048315048217773,
      "learning_rate": 2.0989568649563013e-05,
      "loss": 0.0654,
      "step": 24700
    },
    {
      "epoch": 1.7479296613454558,
      "grad_norm": 0.4025129973888397,
      "learning_rate": 2.0872098486984308e-05,
      "loss": 0.0664,
      "step": 24800
    },
    {
      "epoch": 1.7549776227226275,
      "grad_norm": 0.4508349895477295,
      "learning_rate": 2.0754628324405602e-05,
      "loss": 0.074,
      "step": 24900
    },
    {
      "epoch": 1.7620255840997991,
      "grad_norm": 0.5351043343544006,
      "learning_rate": 2.0637158161826896e-05,
      "loss": 0.0676,
      "step": 25000
    },
    {
      "epoch": 1.7620255840997991,
      "eval_loss": 0.21540683507919312,
      "eval_runtime": 37.5889,
      "eval_samples_per_second": 53.207,
      "eval_steps_per_second": 13.302,
      "step": 25000
    },
    {
      "epoch": 1.7690735454769708,
      "grad_norm": 0.5700446367263794,
      "learning_rate": 2.051968799924819e-05,
      "loss": 0.0655,
      "step": 25100
    },
    {
      "epoch": 1.7761215068541425,
      "grad_norm": 0.30865636467933655,
      "learning_rate": 2.0402217836669488e-05,
      "loss": 0.0647,
      "step": 25200
    },
    {
      "epoch": 1.7831694682313142,
      "grad_norm": 0.4116666316986084,
      "learning_rate": 2.0284747674090782e-05,
      "loss": 0.0721,
      "step": 25300
    },
    {
      "epoch": 1.7902174296084858,
      "grad_norm": 0.6244142651557922,
      "learning_rate": 2.0167277511512077e-05,
      "loss": 0.0639,
      "step": 25400
    },
    {
      "epoch": 1.7972653909856575,
      "grad_norm": 0.5228903293609619,
      "learning_rate": 2.004980734893337e-05,
      "loss": 0.0624,
      "step": 25500
    },
    {
      "epoch": 1.7972653909856575,
      "eval_loss": 0.21395577490329742,
      "eval_runtime": 37.8581,
      "eval_samples_per_second": 52.829,
      "eval_steps_per_second": 13.207,
      "step": 25500
    },
    {
      "epoch": 1.8043133523628292,
      "grad_norm": 0.550466001033783,
      "learning_rate": 1.9932337186354665e-05,
      "loss": 0.0657,
      "step": 25600
    },
    {
      "epoch": 1.8113613137400009,
      "grad_norm": 0.6867873072624207,
      "learning_rate": 1.9814867023775963e-05,
      "loss": 0.0661,
      "step": 25700
    },
    {
      "epoch": 1.8184092751171723,
      "grad_norm": 0.3710528314113617,
      "learning_rate": 1.9697396861197257e-05,
      "loss": 0.069,
      "step": 25800
    },
    {
      "epoch": 1.825457236494344,
      "grad_norm": 0.3748973608016968,
      "learning_rate": 1.9579926698618555e-05,
      "loss": 0.0629,
      "step": 25900
    },
    {
      "epoch": 1.8325051978715157,
      "grad_norm": 0.40695586800575256,
      "learning_rate": 1.9462456536039846e-05,
      "loss": 0.0667,
      "step": 26000
    },
    {
      "epoch": 1.8325051978715157,
      "eval_loss": 0.21524132788181305,
      "eval_runtime": 39.6729,
      "eval_samples_per_second": 50.412,
      "eval_steps_per_second": 12.603,
      "step": 26000
    },
    {
      "epoch": 1.8395531592486873,
      "grad_norm": 0.3424617350101471,
      "learning_rate": 1.934498637346114e-05,
      "loss": 0.0653,
      "step": 26100
    },
    {
      "epoch": 1.846601120625859,
      "grad_norm": 0.4763351082801819,
      "learning_rate": 1.9227516210882438e-05,
      "loss": 0.0713,
      "step": 26200
    },
    {
      "epoch": 1.8536490820030305,
      "grad_norm": 0.3382203280925751,
      "learning_rate": 1.9110046048303732e-05,
      "loss": 0.0634,
      "step": 26300
    },
    {
      "epoch": 1.8606970433802021,
      "grad_norm": 0.5780208706855774,
      "learning_rate": 1.899257588572503e-05,
      "loss": 0.0657,
      "step": 26400
    },
    {
      "epoch": 1.8677450047573738,
      "grad_norm": 0.3935317099094391,
      "learning_rate": 1.887510572314632e-05,
      "loss": 0.0716,
      "step": 26500
    },
    {
      "epoch": 1.8677450047573738,
      "eval_loss": 0.21405236423015594,
      "eval_runtime": 37.7426,
      "eval_samples_per_second": 52.99,
      "eval_steps_per_second": 13.248,
      "step": 26500
    },
    {
      "epoch": 1.8747929661345455,
      "grad_norm": 0.3499087989330292,
      "learning_rate": 1.8757635560567615e-05,
      "loss": 0.066,
      "step": 26600
    },
    {
      "epoch": 1.8818409275117172,
      "grad_norm": 0.3156397342681885,
      "learning_rate": 1.8640165397988912e-05,
      "loss": 0.0668,
      "step": 26700
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.3786543607711792,
      "learning_rate": 1.8522695235410207e-05,
      "loss": 0.0643,
      "step": 26800
    },
    {
      "epoch": 1.8959368502660605,
      "grad_norm": 0.5599560141563416,
      "learning_rate": 1.8405225072831504e-05,
      "loss": 0.0665,
      "step": 26900
    },
    {
      "epoch": 1.9029848116432322,
      "grad_norm": 0.3919510841369629,
      "learning_rate": 1.82877549102528e-05,
      "loss": 0.0621,
      "step": 27000
    },
    {
      "epoch": 1.9029848116432322,
      "eval_loss": 0.21476012468338013,
      "eval_runtime": 37.547,
      "eval_samples_per_second": 53.267,
      "eval_steps_per_second": 13.317,
      "step": 27000
    },
    {
      "epoch": 1.9100327730204039,
      "grad_norm": 0.3636305630207062,
      "learning_rate": 1.817028474767409e-05,
      "loss": 0.0645,
      "step": 27100
    },
    {
      "epoch": 1.9170807343975755,
      "grad_norm": 0.34555986523628235,
      "learning_rate": 1.8052814585095387e-05,
      "loss": 0.067,
      "step": 27200
    },
    {
      "epoch": 1.9241286957747472,
      "grad_norm": 0.4094645380973816,
      "learning_rate": 1.793534442251668e-05,
      "loss": 0.0596,
      "step": 27300
    },
    {
      "epoch": 1.9311766571519189,
      "grad_norm": 0.3675788938999176,
      "learning_rate": 1.781787425993798e-05,
      "loss": 0.0642,
      "step": 27400
    },
    {
      "epoch": 1.9382246185290906,
      "grad_norm": 0.6021401286125183,
      "learning_rate": 1.7700404097359273e-05,
      "loss": 0.0665,
      "step": 27500
    },
    {
      "epoch": 1.9382246185290906,
      "eval_loss": 0.21564650535583496,
      "eval_runtime": 37.8045,
      "eval_samples_per_second": 52.904,
      "eval_steps_per_second": 13.226,
      "step": 27500
    },
    {
      "epoch": 1.9452725799062622,
      "grad_norm": 0.2735878527164459,
      "learning_rate": 1.7582933934780564e-05,
      "loss": 0.0657,
      "step": 27600
    },
    {
      "epoch": 1.952320541283434,
      "grad_norm": 0.432964026927948,
      "learning_rate": 1.7465463772201862e-05,
      "loss": 0.0629,
      "step": 27700
    },
    {
      "epoch": 1.9593685026606056,
      "grad_norm": 0.49763646721839905,
      "learning_rate": 1.7347993609623156e-05,
      "loss": 0.061,
      "step": 27800
    },
    {
      "epoch": 1.966416464037777,
      "grad_norm": 0.5294588208198547,
      "learning_rate": 1.7230523447044454e-05,
      "loss": 0.0617,
      "step": 27900
    },
    {
      "epoch": 1.9734644254149487,
      "grad_norm": 0.4692681133747101,
      "learning_rate": 1.7113053284465748e-05,
      "loss": 0.0616,
      "step": 28000
    },
    {
      "epoch": 1.9734644254149487,
      "eval_loss": 0.21699532866477966,
      "eval_runtime": 36.6869,
      "eval_samples_per_second": 54.515,
      "eval_steps_per_second": 13.629,
      "step": 28000
    },
    {
      "epoch": 1.9805123867921204,
      "grad_norm": 0.41337519884109497,
      "learning_rate": 1.699558312188704e-05,
      "loss": 0.0617,
      "step": 28100
    },
    {
      "epoch": 1.987560348169292,
      "grad_norm": 0.34357908368110657,
      "learning_rate": 1.6878112959308336e-05,
      "loss": 0.0615,
      "step": 28200
    },
    {
      "epoch": 1.9946083095464637,
      "grad_norm": 0.3740343451499939,
      "learning_rate": 1.676064279672963e-05,
      "loss": 0.0621,
      "step": 28300
    },
    {
      "epoch": 2.001691510730521,
      "grad_norm": 0.36142322421073914,
      "learning_rate": 1.664317263415093e-05,
      "loss": 0.0601,
      "step": 28400
    },
    {
      "epoch": 2.0087394721076928,
      "grad_norm": 0.4119393825531006,
      "learning_rate": 1.6525702471572223e-05,
      "loss": 0.0538,
      "step": 28500
    },
    {
      "epoch": 2.0087394721076928,
      "eval_loss": 0.2198566496372223,
      "eval_runtime": 36.5069,
      "eval_samples_per_second": 54.784,
      "eval_steps_per_second": 13.696,
      "step": 28500
    },
    {
      "epoch": 2.0157874334848644,
      "grad_norm": 0.34477606415748596,
      "learning_rate": 1.6408232308993517e-05,
      "loss": 0.0505,
      "step": 28600
    },
    {
      "epoch": 2.022835394862036,
      "grad_norm": 0.3374474048614502,
      "learning_rate": 1.629076214641481e-05,
      "loss": 0.0513,
      "step": 28700
    },
    {
      "epoch": 2.029883356239208,
      "grad_norm": 0.2848169505596161,
      "learning_rate": 1.6173291983836105e-05,
      "loss": 0.0504,
      "step": 28800
    },
    {
      "epoch": 2.0369313176163795,
      "grad_norm": 0.3639135956764221,
      "learning_rate": 1.6055821821257403e-05,
      "loss": 0.0506,
      "step": 28900
    },
    {
      "epoch": 2.043979278993551,
      "grad_norm": 0.31142571568489075,
      "learning_rate": 1.5938351658678697e-05,
      "loss": 0.0518,
      "step": 29000
    },
    {
      "epoch": 2.043979278993551,
      "eval_loss": 0.22143149375915527,
      "eval_runtime": 36.7674,
      "eval_samples_per_second": 54.396,
      "eval_steps_per_second": 13.599,
      "step": 29000
    },
    {
      "epoch": 2.051027240370723,
      "grad_norm": 0.2920089364051819,
      "learning_rate": 1.582088149609999e-05,
      "loss": 0.0509,
      "step": 29100
    },
    {
      "epoch": 2.0580752017478945,
      "grad_norm": 0.3754512071609497,
      "learning_rate": 1.5703411333521286e-05,
      "loss": 0.0502,
      "step": 29200
    },
    {
      "epoch": 2.065123163125066,
      "grad_norm": 0.3391459286212921,
      "learning_rate": 1.558594117094258e-05,
      "loss": 0.0478,
      "step": 29300
    },
    {
      "epoch": 2.072171124502238,
      "grad_norm": 0.32514268159866333,
      "learning_rate": 1.5468471008363878e-05,
      "loss": 0.0498,
      "step": 29400
    },
    {
      "epoch": 2.0792190858794095,
      "grad_norm": 0.4721079170703888,
      "learning_rate": 1.5351000845785172e-05,
      "loss": 0.0525,
      "step": 29500
    },
    {
      "epoch": 2.0792190858794095,
      "eval_loss": 0.2217203825712204,
      "eval_runtime": 36.3171,
      "eval_samples_per_second": 55.07,
      "eval_steps_per_second": 13.768,
      "step": 29500
    },
    {
      "epoch": 2.086267047256581,
      "grad_norm": 0.5448163151741028,
      "learning_rate": 1.5233530683206465e-05,
      "loss": 0.052,
      "step": 29600
    },
    {
      "epoch": 2.093315008633753,
      "grad_norm": 0.2944222688674927,
      "learning_rate": 1.5116060520627762e-05,
      "loss": 0.0494,
      "step": 29700
    },
    {
      "epoch": 2.1003629700109245,
      "grad_norm": 0.30830568075180054,
      "learning_rate": 1.4999765059674844e-05,
      "loss": 0.0512,
      "step": 29800
    },
    {
      "epoch": 2.107410931388096,
      "grad_norm": 0.37770381569862366,
      "learning_rate": 1.4882294897096138e-05,
      "loss": 0.0534,
      "step": 29900
    },
    {
      "epoch": 2.1144588927652674,
      "grad_norm": 0.43522748351097107,
      "learning_rate": 1.4764824734517433e-05,
      "loss": 0.0495,
      "step": 30000
    },
    {
      "epoch": 2.1144588927652674,
      "eval_loss": 0.22101736068725586,
      "eval_runtime": 36.2727,
      "eval_samples_per_second": 55.138,
      "eval_steps_per_second": 13.784,
      "step": 30000
    },
    {
      "epoch": 2.121506854142439,
      "grad_norm": 0.596811056137085,
      "learning_rate": 1.4647354571938729e-05,
      "loss": 0.047,
      "step": 30100
    },
    {
      "epoch": 2.128554815519611,
      "grad_norm": 0.2640475034713745,
      "learning_rate": 1.4529884409360023e-05,
      "loss": 0.0499,
      "step": 30200
    },
    {
      "epoch": 2.1356027768967825,
      "grad_norm": 0.37070268392562866,
      "learning_rate": 1.4412414246781319e-05,
      "loss": 0.0523,
      "step": 30300
    },
    {
      "epoch": 2.142650738273954,
      "grad_norm": 0.4366331398487091,
      "learning_rate": 1.4294944084202613e-05,
      "loss": 0.0499,
      "step": 30400
    },
    {
      "epoch": 2.149698699651126,
      "grad_norm": 0.46675801277160645,
      "learning_rate": 1.4177473921623907e-05,
      "loss": 0.0484,
      "step": 30500
    },
    {
      "epoch": 2.149698699651126,
      "eval_loss": 0.2218068242073059,
      "eval_runtime": 36.4701,
      "eval_samples_per_second": 54.839,
      "eval_steps_per_second": 13.71,
      "step": 30500
    },
    {
      "epoch": 2.1567466610282975,
      "grad_norm": 0.5169827938079834,
      "learning_rate": 1.4060003759045203e-05,
      "loss": 0.0515,
      "step": 30600
    },
    {
      "epoch": 2.163794622405469,
      "grad_norm": 0.3081369996070862,
      "learning_rate": 1.3942533596466498e-05,
      "loss": 0.0434,
      "step": 30700
    },
    {
      "epoch": 2.170842583782641,
      "grad_norm": 0.2886173725128174,
      "learning_rate": 1.3825063433887794e-05,
      "loss": 0.0557,
      "step": 30800
    },
    {
      "epoch": 2.1778905451598125,
      "grad_norm": 0.3669348657131195,
      "learning_rate": 1.3707593271309088e-05,
      "loss": 0.0487,
      "step": 30900
    },
    {
      "epoch": 2.184938506536984,
      "grad_norm": 0.3856334388256073,
      "learning_rate": 1.3590123108730382e-05,
      "loss": 0.0524,
      "step": 31000
    },
    {
      "epoch": 2.184938506536984,
      "eval_loss": 0.22281302511692047,
      "eval_runtime": 36.4462,
      "eval_samples_per_second": 54.875,
      "eval_steps_per_second": 13.719,
      "step": 31000
    },
    {
      "epoch": 2.191986467914156,
      "grad_norm": 0.33123043179512024,
      "learning_rate": 1.3472652946151678e-05,
      "loss": 0.0492,
      "step": 31100
    },
    {
      "epoch": 2.1990344292913275,
      "grad_norm": 0.3071320950984955,
      "learning_rate": 1.3355182783572972e-05,
      "loss": 0.0497,
      "step": 31200
    },
    {
      "epoch": 2.206082390668499,
      "grad_norm": 0.45191988348960876,
      "learning_rate": 1.3237712620994268e-05,
      "loss": 0.0458,
      "step": 31300
    },
    {
      "epoch": 2.213130352045671,
      "grad_norm": 0.34040212631225586,
      "learning_rate": 1.3120242458415563e-05,
      "loss": 0.0528,
      "step": 31400
    },
    {
      "epoch": 2.2201783134228426,
      "grad_norm": 0.2488858848810196,
      "learning_rate": 1.3002772295836857e-05,
      "loss": 0.0463,
      "step": 31500
    },
    {
      "epoch": 2.2201783134228426,
      "eval_loss": 0.2205556333065033,
      "eval_runtime": 36.9367,
      "eval_samples_per_second": 54.147,
      "eval_steps_per_second": 13.537,
      "step": 31500
    },
    {
      "epoch": 2.2272262748000142,
      "grad_norm": 0.31499481201171875,
      "learning_rate": 1.2885302133258153e-05,
      "loss": 0.0489,
      "step": 31600
    },
    {
      "epoch": 2.234274236177186,
      "grad_norm": 0.43408849835395813,
      "learning_rate": 1.2767831970679447e-05,
      "loss": 0.0513,
      "step": 31700
    },
    {
      "epoch": 2.2413221975543576,
      "grad_norm": 0.3584020435810089,
      "learning_rate": 1.2650361808100745e-05,
      "loss": 0.0442,
      "step": 31800
    },
    {
      "epoch": 2.2483701589315293,
      "grad_norm": 0.40009212493896484,
      "learning_rate": 1.2532891645522037e-05,
      "loss": 0.0469,
      "step": 31900
    },
    {
      "epoch": 2.2554181203087005,
      "grad_norm": 0.26293545961380005,
      "learning_rate": 1.2415421482943333e-05,
      "loss": 0.047,
      "step": 32000
    },
    {
      "epoch": 2.2554181203087005,
      "eval_loss": 0.22191113233566284,
      "eval_runtime": 36.5057,
      "eval_samples_per_second": 54.786,
      "eval_steps_per_second": 13.697,
      "step": 32000
    },
    {
      "epoch": 2.262466081685872,
      "grad_norm": 0.5312800407409668,
      "learning_rate": 1.229795132036463e-05,
      "loss": 0.0454,
      "step": 32100
    },
    {
      "epoch": 2.269514043063044,
      "grad_norm": 0.4036692678928375,
      "learning_rate": 1.2180481157785922e-05,
      "loss": 0.0483,
      "step": 32200
    },
    {
      "epoch": 2.2765620044402155,
      "grad_norm": 0.42422643303871155,
      "learning_rate": 1.2063010995207218e-05,
      "loss": 0.0513,
      "step": 32300
    },
    {
      "epoch": 2.283609965817387,
      "grad_norm": 0.3870474100112915,
      "learning_rate": 1.1945540832628512e-05,
      "loss": 0.0534,
      "step": 32400
    },
    {
      "epoch": 2.290657927194559,
      "grad_norm": 0.35474923253059387,
      "learning_rate": 1.1828070670049808e-05,
      "loss": 0.0483,
      "step": 32500
    },
    {
      "epoch": 2.290657927194559,
      "eval_loss": 0.22123663127422333,
      "eval_runtime": 36.9502,
      "eval_samples_per_second": 54.127,
      "eval_steps_per_second": 13.532,
      "step": 32500
    },
    {
      "epoch": 2.2977058885717305,
      "grad_norm": 0.3621489405632019,
      "learning_rate": 1.1710600507471104e-05,
      "loss": 0.0515,
      "step": 32600
    },
    {
      "epoch": 2.304753849948902,
      "grad_norm": 0.2916513681411743,
      "learning_rate": 1.1593130344892397e-05,
      "loss": 0.0483,
      "step": 32700
    },
    {
      "epoch": 2.311801811326074,
      "grad_norm": 0.35675308108329773,
      "learning_rate": 1.1475660182313693e-05,
      "loss": 0.0474,
      "step": 32800
    },
    {
      "epoch": 2.3188497727032455,
      "grad_norm": 0.2616024315357208,
      "learning_rate": 1.1358190019734989e-05,
      "loss": 0.0414,
      "step": 32900
    },
    {
      "epoch": 2.3258977340804172,
      "grad_norm": 0.36815550923347473,
      "learning_rate": 1.1240719857156283e-05,
      "loss": 0.049,
      "step": 33000
    },
    {
      "epoch": 2.3258977340804172,
      "eval_loss": 0.2216416895389557,
      "eval_runtime": 36.7281,
      "eval_samples_per_second": 54.454,
      "eval_steps_per_second": 13.614,
      "step": 33000
    },
    {
      "epoch": 2.332945695457589,
      "grad_norm": 0.45188409090042114,
      "learning_rate": 1.1123249694577579e-05,
      "loss": 0.0484,
      "step": 33100
    },
    {
      "epoch": 2.3399936568347606,
      "grad_norm": 0.3447410464286804,
      "learning_rate": 1.1005779531998871e-05,
      "loss": 0.0475,
      "step": 33200
    },
    {
      "epoch": 2.3470416182119322,
      "grad_norm": 0.3489241600036621,
      "learning_rate": 1.0888309369420167e-05,
      "loss": 0.0487,
      "step": 33300
    },
    {
      "epoch": 2.354089579589104,
      "grad_norm": 0.3489590883255005,
      "learning_rate": 1.0770839206841463e-05,
      "loss": 0.0492,
      "step": 33400
    },
    {
      "epoch": 2.3611375409662756,
      "grad_norm": 0.30325496196746826,
      "learning_rate": 1.0653369044262758e-05,
      "loss": 0.0452,
      "step": 33500
    },
    {
      "epoch": 2.3611375409662756,
      "eval_loss": 0.22251982986927032,
      "eval_runtime": 36.5911,
      "eval_samples_per_second": 54.658,
      "eval_steps_per_second": 13.665,
      "step": 33500
    },
    {
      "epoch": 2.3681855023434473,
      "grad_norm": 0.3948226273059845,
      "learning_rate": 1.0535898881684054e-05,
      "loss": 0.0487,
      "step": 33600
    },
    {
      "epoch": 2.375233463720619,
      "grad_norm": 0.31797266006469727,
      "learning_rate": 1.0418428719105348e-05,
      "loss": 0.0478,
      "step": 33700
    },
    {
      "epoch": 2.3822814250977906,
      "grad_norm": 0.7111429572105408,
      "learning_rate": 1.0300958556526642e-05,
      "loss": 0.0476,
      "step": 33800
    },
    {
      "epoch": 2.3893293864749623,
      "grad_norm": 0.28931379318237305,
      "learning_rate": 1.0183488393947938e-05,
      "loss": 0.045,
      "step": 33900
    },
    {
      "epoch": 2.396377347852134,
      "grad_norm": 0.4100441336631775,
      "learning_rate": 1.0066018231369232e-05,
      "loss": 0.0475,
      "step": 34000
    },
    {
      "epoch": 2.396377347852134,
      "eval_loss": 0.22286532819271088,
      "eval_runtime": 36.5862,
      "eval_samples_per_second": 54.665,
      "eval_steps_per_second": 13.666,
      "step": 34000
    },
    {
      "epoch": 2.4034253092293056,
      "grad_norm": 0.48298802971839905,
      "learning_rate": 9.948548068790528e-06,
      "loss": 0.0461,
      "step": 34100
    },
    {
      "epoch": 2.4104732706064773,
      "grad_norm": 0.40103042125701904,
      "learning_rate": 9.831077906211822e-06,
      "loss": 0.0471,
      "step": 34200
    },
    {
      "epoch": 2.4175212319836485,
      "grad_norm": 0.31175312399864197,
      "learning_rate": 9.713607743633117e-06,
      "loss": 0.0467,
      "step": 34300
    },
    {
      "epoch": 2.42456919336082,
      "grad_norm": 0.5462220907211304,
      "learning_rate": 9.596137581054413e-06,
      "loss": 0.0498,
      "step": 34400
    },
    {
      "epoch": 2.431617154737992,
      "grad_norm": 0.2979295253753662,
      "learning_rate": 9.478667418475707e-06,
      "loss": 0.0449,
      "step": 34500
    },
    {
      "epoch": 2.431617154737992,
      "eval_loss": 0.22292198240756989,
      "eval_runtime": 36.8785,
      "eval_samples_per_second": 54.232,
      "eval_steps_per_second": 13.558,
      "step": 34500
    },
    {
      "epoch": 2.4386651161151636,
      "grad_norm": 0.38542887568473816,
      "learning_rate": 9.361197255897003e-06,
      "loss": 0.0442,
      "step": 34600
    },
    {
      "epoch": 2.4457130774923352,
      "grad_norm": 0.29825782775878906,
      "learning_rate": 9.243727093318299e-06,
      "loss": 0.0523,
      "step": 34700
    },
    {
      "epoch": 2.452761038869507,
      "grad_norm": 0.3214493691921234,
      "learning_rate": 9.126256930739591e-06,
      "loss": 0.0424,
      "step": 34800
    },
    {
      "epoch": 2.4598090002466786,
      "grad_norm": 0.3799802362918854,
      "learning_rate": 9.008786768160887e-06,
      "loss": 0.0436,
      "step": 34900
    },
    {
      "epoch": 2.4668569616238503,
      "grad_norm": 0.4353179633617401,
      "learning_rate": 8.891316605582182e-06,
      "loss": 0.0475,
      "step": 35000
    },
    {
      "epoch": 2.4668569616238503,
      "eval_loss": 0.22243668138980865,
      "eval_runtime": 36.6159,
      "eval_samples_per_second": 54.621,
      "eval_steps_per_second": 13.655,
      "step": 35000
    },
    {
      "epoch": 2.473904923001022,
      "grad_norm": 0.6144127249717712,
      "learning_rate": 8.773846443003478e-06,
      "loss": 0.0515,
      "step": 35100
    },
    {
      "epoch": 2.4809528843781936,
      "grad_norm": 0.7363667488098145,
      "learning_rate": 8.656376280424774e-06,
      "loss": 0.0483,
      "step": 35200
    },
    {
      "epoch": 2.4880008457553653,
      "grad_norm": 0.3646042048931122,
      "learning_rate": 8.538906117846066e-06,
      "loss": 0.0475,
      "step": 35300
    },
    {
      "epoch": 2.495048807132537,
      "grad_norm": 0.4689048230648041,
      "learning_rate": 8.421435955267362e-06,
      "loss": 0.0422,
      "step": 35400
    },
    {
      "epoch": 2.5020967685097086,
      "grad_norm": 0.22636087238788605,
      "learning_rate": 8.303965792688658e-06,
      "loss": 0.0434,
      "step": 35500
    },
    {
      "epoch": 2.5020967685097086,
      "eval_loss": 0.22327648103237152,
      "eval_runtime": 36.6603,
      "eval_samples_per_second": 54.555,
      "eval_steps_per_second": 13.639,
      "step": 35500
    },
    {
      "epoch": 2.5091447298868803,
      "grad_norm": 0.4447418749332428,
      "learning_rate": 8.186495630109952e-06,
      "loss": 0.0479,
      "step": 35600
    },
    {
      "epoch": 2.516192691264052,
      "grad_norm": 0.7647725939750671,
      "learning_rate": 8.069025467531248e-06,
      "loss": 0.0454,
      "step": 35700
    },
    {
      "epoch": 2.5232406526412237,
      "grad_norm": 0.3157525956630707,
      "learning_rate": 7.951555304952543e-06,
      "loss": 0.0449,
      "step": 35800
    },
    {
      "epoch": 2.5302886140183953,
      "grad_norm": 0.42084944248199463,
      "learning_rate": 7.834085142373837e-06,
      "loss": 0.0509,
      "step": 35900
    },
    {
      "epoch": 2.5373365753955666,
      "grad_norm": 0.30981704592704773,
      "learning_rate": 7.716614979795133e-06,
      "loss": 0.0461,
      "step": 36000
    },
    {
      "epoch": 2.5373365753955666,
      "eval_loss": 0.2212318778038025,
      "eval_runtime": 36.9519,
      "eval_samples_per_second": 54.124,
      "eval_steps_per_second": 13.531,
      "step": 36000
    },
    {
      "epoch": 2.5443845367727382,
      "grad_norm": 0.41192787885665894,
      "learning_rate": 7.599144817216428e-06,
      "loss": 0.0439,
      "step": 36100
    },
    {
      "epoch": 2.55143249814991,
      "grad_norm": 0.23708407580852509,
      "learning_rate": 7.481674654637723e-06,
      "loss": 0.0504,
      "step": 36200
    },
    {
      "epoch": 2.5584804595270816,
      "grad_norm": 0.3761562705039978,
      "learning_rate": 7.3642044920590165e-06,
      "loss": 0.0471,
      "step": 36300
    },
    {
      "epoch": 2.5655284209042533,
      "grad_norm": 0.4838392734527588,
      "learning_rate": 7.246734329480312e-06,
      "loss": 0.0471,
      "step": 36400
    },
    {
      "epoch": 2.572576382281425,
      "grad_norm": 0.3841169774532318,
      "learning_rate": 7.129264166901608e-06,
      "loss": 0.0478,
      "step": 36500
    },
    {
      "epoch": 2.572576382281425,
      "eval_loss": 0.22289840877056122,
      "eval_runtime": 36.7545,
      "eval_samples_per_second": 54.415,
      "eval_steps_per_second": 13.604,
      "step": 36500
    },
    {
      "epoch": 2.5796243436585966,
      "grad_norm": 0.38964709639549255,
      "learning_rate": 7.011794004322903e-06,
      "loss": 0.0508,
      "step": 36600
    },
    {
      "epoch": 2.5866723050357683,
      "grad_norm": 0.27448827028274536,
      "learning_rate": 6.894323841744198e-06,
      "loss": 0.0491,
      "step": 36700
    },
    {
      "epoch": 2.59372026641294,
      "grad_norm": 0.3624477982521057,
      "learning_rate": 6.776853679165493e-06,
      "loss": 0.0493,
      "step": 36800
    },
    {
      "epoch": 2.6007682277901116,
      "grad_norm": 0.2664962708950043,
      "learning_rate": 6.659383516586787e-06,
      "loss": 0.043,
      "step": 36900
    },
    {
      "epoch": 2.6078161891672833,
      "grad_norm": 0.4292316138744354,
      "learning_rate": 6.541913354008082e-06,
      "loss": 0.0453,
      "step": 37000
    },
    {
      "epoch": 2.6078161891672833,
      "eval_loss": 0.2224300652742386,
      "eval_runtime": 37.1158,
      "eval_samples_per_second": 53.885,
      "eval_steps_per_second": 13.471,
      "step": 37000
    },
    {
      "epoch": 2.614864150544455,
      "grad_norm": 0.37722861766815186,
      "learning_rate": 6.4244431914293774e-06,
      "loss": 0.0455,
      "step": 37100
    },
    {
      "epoch": 2.6219121119216267,
      "grad_norm": 0.7613764405250549,
      "learning_rate": 6.3069730288506726e-06,
      "loss": 0.0445,
      "step": 37200
    },
    {
      "epoch": 2.6289600732987983,
      "grad_norm": 0.40993034839630127,
      "learning_rate": 6.189502866271967e-06,
      "loss": 0.0457,
      "step": 37300
    },
    {
      "epoch": 2.63600803467597,
      "grad_norm": 0.30458468198776245,
      "learning_rate": 6.072032703693263e-06,
      "loss": 0.0476,
      "step": 37400
    },
    {
      "epoch": 2.6430559960531417,
      "grad_norm": 0.37174633145332336,
      "learning_rate": 5.954562541114557e-06,
      "loss": 0.0442,
      "step": 37500
    },
    {
      "epoch": 2.6430559960531417,
      "eval_loss": 0.22235547006130219,
      "eval_runtime": 37.2448,
      "eval_samples_per_second": 53.699,
      "eval_steps_per_second": 13.425,
      "step": 37500
    },
    {
      "epoch": 2.6501039574303134,
      "grad_norm": 0.46787089109420776,
      "learning_rate": 5.837092378535852e-06,
      "loss": 0.0463,
      "step": 37600
    },
    {
      "epoch": 2.657151918807485,
      "grad_norm": 0.9093394875526428,
      "learning_rate": 5.719622215957147e-06,
      "loss": 0.0462,
      "step": 37700
    },
    {
      "epoch": 2.6641998801846567,
      "grad_norm": 0.2872472405433655,
      "learning_rate": 5.602152053378442e-06,
      "loss": 0.0464,
      "step": 37800
    },
    {
      "epoch": 2.6712478415618284,
      "grad_norm": 0.4711626470088959,
      "learning_rate": 5.4846818907997375e-06,
      "loss": 0.0414,
      "step": 37900
    },
    {
      "epoch": 2.678295802939,
      "grad_norm": 0.35379910469055176,
      "learning_rate": 5.367211728221032e-06,
      "loss": 0.0448,
      "step": 38000
    },
    {
      "epoch": 2.678295802939,
      "eval_loss": 0.22284649312496185,
      "eval_runtime": 37.1025,
      "eval_samples_per_second": 53.905,
      "eval_steps_per_second": 13.476,
      "step": 38000
    },
    {
      "epoch": 2.6853437643161717,
      "grad_norm": 0.3660088777542114,
      "learning_rate": 5.249741565642327e-06,
      "loss": 0.0416,
      "step": 38100
    },
    {
      "epoch": 2.6923917256933434,
      "grad_norm": 0.2654779553413391,
      "learning_rate": 5.132271403063622e-06,
      "loss": 0.0491,
      "step": 38200
    },
    {
      "epoch": 2.699439687070515,
      "grad_norm": 0.3567426800727844,
      "learning_rate": 5.014801240484917e-06,
      "loss": 0.0452,
      "step": 38300
    },
    {
      "epoch": 2.7064876484476867,
      "grad_norm": 0.3240828812122345,
      "learning_rate": 4.897331077906212e-06,
      "loss": 0.0452,
      "step": 38400
    },
    {
      "epoch": 2.7135356098248584,
      "grad_norm": 0.49736106395721436,
      "learning_rate": 4.7798609153275065e-06,
      "loss": 0.0427,
      "step": 38500
    },
    {
      "epoch": 2.7135356098248584,
      "eval_loss": 0.22224867343902588,
      "eval_runtime": 37.4038,
      "eval_samples_per_second": 53.47,
      "eval_steps_per_second": 13.368,
      "step": 38500
    },
    {
      "epoch": 2.7205835712020296,
      "grad_norm": 0.4183509051799774,
      "learning_rate": 4.662390752748802e-06,
      "loss": 0.0426,
      "step": 38600
    },
    {
      "epoch": 2.7276315325792013,
      "grad_norm": 0.30680978298187256,
      "learning_rate": 4.544920590170098e-06,
      "loss": 0.0448,
      "step": 38700
    },
    {
      "epoch": 2.734679493956373,
      "grad_norm": 0.45546895265579224,
      "learning_rate": 4.427450427591392e-06,
      "loss": 0.0461,
      "step": 38800
    },
    {
      "epoch": 2.7417274553335447,
      "grad_norm": 0.3527732789516449,
      "learning_rate": 4.309980265012687e-06,
      "loss": 0.0438,
      "step": 38900
    },
    {
      "epoch": 2.7487754167107163,
      "grad_norm": 0.5949633121490479,
      "learning_rate": 4.192510102433981e-06,
      "loss": 0.0492,
      "step": 39000
    },
    {
      "epoch": 2.7487754167107163,
      "eval_loss": 0.22175705432891846,
      "eval_runtime": 37.2953,
      "eval_samples_per_second": 53.626,
      "eval_steps_per_second": 13.407,
      "step": 39000
    },
    {
      "epoch": 2.755823378087888,
      "grad_norm": 0.3698071241378784,
      "learning_rate": 4.075039939855277e-06,
      "loss": 0.0436,
      "step": 39100
    },
    {
      "epoch": 2.7628713394650597,
      "grad_norm": 0.25071606040000916,
      "learning_rate": 3.957569777276572e-06,
      "loss": 0.0463,
      "step": 39200
    },
    {
      "epoch": 2.7699193008422314,
      "grad_norm": 0.235067680478096,
      "learning_rate": 3.840099614697867e-06,
      "loss": 0.044,
      "step": 39300
    },
    {
      "epoch": 2.776967262219403,
      "grad_norm": 0.35464876890182495,
      "learning_rate": 3.722629452119162e-06,
      "loss": 0.0425,
      "step": 39400
    },
    {
      "epoch": 2.7840152235965747,
      "grad_norm": 0.36215919256210327,
      "learning_rate": 3.6051592895404572e-06,
      "loss": 0.0432,
      "step": 39500
    },
    {
      "epoch": 2.7840152235965747,
      "eval_loss": 0.22243890166282654,
      "eval_runtime": 37.2469,
      "eval_samples_per_second": 53.696,
      "eval_steps_per_second": 13.424,
      "step": 39500
    },
    {
      "epoch": 2.7910631849737464,
      "grad_norm": 0.5215280055999756,
      "learning_rate": 3.487689126961752e-06,
      "loss": 0.0424,
      "step": 39600
    },
    {
      "epoch": 2.798111146350918,
      "grad_norm": 0.30326125025749207,
      "learning_rate": 3.370218964383047e-06,
      "loss": 0.0467,
      "step": 39700
    },
    {
      "epoch": 2.8051591077280897,
      "grad_norm": 0.39286506175994873,
      "learning_rate": 3.2527488018043417e-06,
      "loss": 0.044,
      "step": 39800
    },
    {
      "epoch": 2.8122070691052614,
      "grad_norm": 0.3093940019607544,
      "learning_rate": 3.135278639225637e-06,
      "loss": 0.0441,
      "step": 39900
    },
    {
      "epoch": 2.819255030482433,
      "grad_norm": 0.4160419702529907,
      "learning_rate": 3.0178084766469316e-06,
      "loss": 0.0457,
      "step": 40000
    },
    {
      "epoch": 2.819255030482433,
      "eval_loss": 0.2223287671804428,
      "eval_runtime": 37.1952,
      "eval_samples_per_second": 53.77,
      "eval_steps_per_second": 13.443,
      "step": 40000
    },
    {
      "epoch": 2.8263029918596048,
      "grad_norm": 0.2945302128791809,
      "learning_rate": 2.9003383140682267e-06,
      "loss": 0.0427,
      "step": 40100
    },
    {
      "epoch": 2.833350953236776,
      "grad_norm": 0.41713017225265503,
      "learning_rate": 2.7828681514895218e-06,
      "loss": 0.0455,
      "step": 40200
    },
    {
      "epoch": 2.8403989146139477,
      "grad_norm": 0.2323674112558365,
      "learning_rate": 2.665397988910817e-06,
      "loss": 0.0461,
      "step": 40300
    },
    {
      "epoch": 2.8474468759911193,
      "grad_norm": 0.4816749095916748,
      "learning_rate": 2.5479278263321116e-06,
      "loss": 0.0451,
      "step": 40400
    },
    {
      "epoch": 2.854494837368291,
      "grad_norm": 0.4492977559566498,
      "learning_rate": 2.4304576637534067e-06,
      "loss": 0.0494,
      "step": 40500
    },
    {
      "epoch": 2.854494837368291,
      "eval_loss": 0.2227485626935959,
      "eval_runtime": 37.0291,
      "eval_samples_per_second": 54.012,
      "eval_steps_per_second": 13.503,
      "step": 40500
    },
    {
      "epoch": 2.8615427987454627,
      "grad_norm": 0.5347491502761841,
      "learning_rate": 2.312987501174702e-06,
      "loss": 0.0438,
      "step": 40600
    },
    {
      "epoch": 2.8685907601226344,
      "grad_norm": 0.3176407814025879,
      "learning_rate": 2.195517338595997e-06,
      "loss": 0.043,
      "step": 40700
    },
    {
      "epoch": 2.875638721499806,
      "grad_norm": 0.2553495168685913,
      "learning_rate": 2.0780471760172916e-06,
      "loss": 0.0406,
      "step": 40800
    },
    {
      "epoch": 2.8826866828769777,
      "grad_norm": 0.3594983220100403,
      "learning_rate": 1.9605770134385867e-06,
      "loss": 0.0408,
      "step": 40900
    },
    {
      "epoch": 2.8897346442541494,
      "grad_norm": 0.46666914224624634,
      "learning_rate": 1.8431068508598814e-06,
      "loss": 0.0435,
      "step": 41000
    },
    {
      "epoch": 2.8897346442541494,
      "eval_loss": 0.22275234758853912,
      "eval_runtime": 37.0104,
      "eval_samples_per_second": 54.039,
      "eval_steps_per_second": 13.51,
      "step": 41000
    },
    {
      "epoch": 2.896782605631321,
      "grad_norm": 0.374087929725647,
      "learning_rate": 1.7256366882811768e-06,
      "loss": 0.0476,
      "step": 41100
    },
    {
      "epoch": 2.9038305670084927,
      "grad_norm": 0.4830470085144043,
      "learning_rate": 1.6081665257024717e-06,
      "loss": 0.0458,
      "step": 41200
    },
    {
      "epoch": 2.9108785283856644,
      "grad_norm": 0.32938331365585327,
      "learning_rate": 1.4906963631237666e-06,
      "loss": 0.0463,
      "step": 41300
    },
    {
      "epoch": 2.917926489762836,
      "grad_norm": 0.345511794090271,
      "learning_rate": 1.3732262005450617e-06,
      "loss": 0.0453,
      "step": 41400
    },
    {
      "epoch": 2.9249744511400078,
      "grad_norm": 0.3908127248287201,
      "learning_rate": 1.2557560379663566e-06,
      "loss": 0.043,
      "step": 41500
    },
    {
      "epoch": 2.9249744511400078,
      "eval_loss": 0.22216495871543884,
      "eval_runtime": 37.2702,
      "eval_samples_per_second": 53.662,
      "eval_steps_per_second": 13.416,
      "step": 41500
    },
    {
      "epoch": 2.9320224125171794,
      "grad_norm": 0.41348859667778015,
      "learning_rate": 1.1382858753876517e-06,
      "loss": 0.0467,
      "step": 41600
    },
    {
      "epoch": 2.939070373894351,
      "grad_norm": 0.2864152193069458,
      "learning_rate": 1.0208157128089466e-06,
      "loss": 0.0439,
      "step": 41700
    },
    {
      "epoch": 2.946118335271523,
      "grad_norm": 0.19007234275341034,
      "learning_rate": 9.033455502302416e-07,
      "loss": 0.0406,
      "step": 41800
    },
    {
      "epoch": 2.9531662966486945,
      "grad_norm": 0.40117454528808594,
      "learning_rate": 7.858753876515365e-07,
      "loss": 0.0507,
      "step": 41900
    },
    {
      "epoch": 2.960214258025866,
      "grad_norm": 0.5050511360168457,
      "learning_rate": 6.684052250728315e-07,
      "loss": 0.0423,
      "step": 42000
    },
    {
      "epoch": 2.960214258025866,
      "eval_loss": 0.22146426141262054,
      "eval_runtime": 37.1747,
      "eval_samples_per_second": 53.8,
      "eval_steps_per_second": 13.45,
      "step": 42000
    },
    {
      "epoch": 2.967262219403038,
      "grad_norm": 0.4341180920600891,
      "learning_rate": 5.509350624941265e-07,
      "loss": 0.0479,
      "step": 42100
    },
    {
      "epoch": 2.9743101807802095,
      "grad_norm": 0.37979400157928467,
      "learning_rate": 4.3346489991542154e-07,
      "loss": 0.044,
      "step": 42200
    },
    {
      "epoch": 2.981358142157381,
      "grad_norm": 0.24097880721092224,
      "learning_rate": 3.159947373367165e-07,
      "loss": 0.0436,
      "step": 42300
    },
    {
      "epoch": 2.988406103534553,
      "grad_norm": 0.33656173944473267,
      "learning_rate": 1.9852457475801148e-07,
      "loss": 0.0411,
      "step": 42400
    },
    {
      "epoch": 2.9954540649117245,
      "grad_norm": 0.22252970933914185,
      "learning_rate": 8.105441217930645e-08,
      "loss": 0.0404,
      "step": 42500
    },
    {
      "epoch": 2.9954540649117245,
      "eval_loss": 0.22195862233638763,
      "eval_runtime": 36.9851,
      "eval_samples_per_second": 54.076,
      "eval_steps_per_second": 13.519,
      "step": 42500
    }
  ],
  "logging_steps": 100,
  "max_steps": 42564,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4628288468300595e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
